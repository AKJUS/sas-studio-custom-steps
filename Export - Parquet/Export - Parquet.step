{"creationTimeStamp":"2023-12-04T17:11:20.393Z","modifiedTimeStamp":"2023-12-12T10:33:08.853Z","createdBy":"Neil.Griffin@sas.com","modifiedBy":"Neil.Griffin@sas.com","name":"Export - Parquet.step","displayName":"Export - Parquet.step","localDisplayName":"Export - Parquet.step","properties":{},"links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","uri":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","uri":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","uri":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","uri":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","uri":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","uri":"/dataFlows/steps/7b8bcf9d-2cc1-42e1-85f2-d939cb6e900e","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":0.0,"version":2,"type":"code","flowMetadata":{"inputPorts":[{"name":"inTable","displayName":"Input table","localDisplayName":"Input table","description":"Input table","localDescription":"Input table","minEntries":1,"maxEntries":1,"defaultEntries":0,"type":"table"}],"outputPorts":[]},"ui":"{\n\t\"showPageContentOnly\": true,\n\t\"pages\": [\n\t\t{\n\t\t\t\"id\": \"options\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Export options\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"inTable\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Select an input table:\",\n\t\t\t\t\t\"required\": true\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"folder\",\n\t\t\t\t\t\"type\": \"path\",\n\t\t\t\t\t\"label\": \"Export folder:\",\n\t\t\t\t\t\"pathtype\": \"folder\",\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"replace\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Delete output data if it already exists\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"partition_type\",\n\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\"label\": \"Partition type:\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"None\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"DIRECTORY\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"FILENAME\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"HIVE\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"partition_by\",\n\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\"label\": \"Partition by:\",\n\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\"columntype\": \"a\",\n\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\"min\": null,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"enabled\": [\n\t\t\t\t\t\t\"$partition_type\",\n\t\t\t\t\t\t\"!=\",\n\t\t\t\t\t\t\"None\"\n\t\t\t\t\t],\n\t\t\t\t\t\"table\": \"inTable\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"file_name_extension\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"File name extension (non-partitioned data only):\",\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"enabled\": [\n\t\t\t\t\t\t\"$partition_type\",\n\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\"None\"\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"compress\",\n\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\"label\": \"Compression type:\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"BROTLI\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"GZIP\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"LZ4\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"LZ4_HADP\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"SNAPPY\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ZSTD\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"string\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Export SAS character columns as Parquet STRING logical type\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"about\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"About\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"abouttext\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"EXPORT - PARQUET\\n\\nDESCRIPTION\\n\\nThe Export - Parquet custom step allows SAS Studio users to export a SAS dataset to Parquet file(s) on a file system using the SAS Viya LIBNAME Engine for Parquet.\\n\\nAll relevant LIBNAME options (folder, compression type, filename extension) and data set options (partition type, partition by) are available in the custom step dialog.\\n\\nThe custom step also includes options to:\\n- Delete output data if it already exists\\n- Cast SAS character variables to Parquet logical STRING type for compatibility with other Parquet data consumers\\n\\nIf the Python PyArrow module is available, the Parquet schema and files metadata will be reported in the log.\\n\\nLimitations:\\n- Does not support export to AWS S3, ADLS or GCS object storage. For export to ADLS, do check out the ADLS File Writer custom step by Alfredo Lorie\\n\\nREQUIREMENTS\\n\\nTested on SAS Viya version Stable 2023.11, with Python 3.9.16 and PyArrow 13.0.0.\\n\\n- Requires SAS Viya 2023.10 or above (the DBTYPE option was added in 2023.10)\\n- Python must be configured on the SAS Viya platform\\n- PyArrow is not required, but if module is installed, Parquet metadata will be reported in the log\\n\\nUSAGE\\n\\nCustom step options\\n\\nInput table\\nDefault: None\\nDescription: Input table, connect using the input port in the Flow\\n\\nExport folder\\nDefault: None\\nTarget folder for the output data. See notes on output file naming below\\n\\nDelete output data if it already exists\\nDefault: True\\nThe target location must be empty for partitioned data. Check this box to delete data in the export folder if it exists\\n\\nPartition type\\nDefault: None\\nDescription: Can be DIRECTORY, FILENAME, HIVE. Details in the PARTITION_TYPE option documentation\\n\\nPartition by\\nDefault: -\\nDescription: One or more columns that determine the table's partitions. Details in the PARTITION_BY option documentation\\n\\nFile name extension (non-partitioned data only)\\nDefault: parquet\\nDescription: Specifies the file extension for SAS to write Parquet files. Details in the FILE_NAME_EXTENSION option documentation\\n\\nCompression type\\nDefault: SNAPPY\\nDescription: Controls the compression type. Details in the COMPRESS option documentation\\n\\nExport SAS character columns as Parquet STRING logical type\\nDefault: True\\nDescription: If set, this option will cast SAS dataset character variables to Parquet STRING logical type. (By default, the SAS LIBNAME Engines for Parquet uses a BYTE_ARRAY)\\n\\nOUTPUT\\nIf the SASHELP.PRDSAL3 data set is exported to the folder /shared-data/pqt, the following files are created with each partition type:\\n\\nNone\\n./prdsal3.parquet\\n\\nDIRECTORY\\n./prdsal3/Canada/part0.parquet\\n./prdsal3/Mexico/part0.parquet\\n./prdsal3/U.S.A./part0.parquet\\n\\nFILENAME\\n./prdsal3/Canada_part0.parquet\\n./prdsal3/Mexico_part0.parquet\\n./prdsal3/U.S.A._part0.parquet\\n\\nHIVE\\n./prdsal3/COUNTRY=Canada/part0.parquet\\n./prdsal3/COUNTRY=Mexico/part0.parquet\\n./prdsal3/COUNTRY=U.S.A./part0.parquet\\n\\nCHANGE LOG\\n\\nVersion 1.0 (12DEC2023)\\n- Initial version\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t],\n\t\"syntaxversion\": \"1.3.0\",\n\t\"values\": {\n\t\t\"folder\": \"\",\n\t\t\"replace\": true,\n\t\t\"partition_type\": {\n\t\t\t\"value\": \"None\"\n\t\t},\n\t\t\"partition_by\": [],\n\t\t\"file_name_extension\": \"parquet\",\n\t\t\"compress\": {\n\t\t\t\"value\": \"SNAPPY\"\n\t\t},\n\t\t\"string\": true\n\t}\n}","templates":{"SAS":"* -----------------------------------------------------------------------------;\n* Export SAS dataset to Parquet;\n* https://go.documentation.sas.com/doc/en/pgmsascdc/v_045/enghdff/titlepage.htm;\n* -----------------------------------------------------------------------------;\n\n* Print macro variables passed from custom step;\n%put NOTE: &=inTable;\n%put NOTE: &=folder;\n%put NOTE: &=replace;\n%put NOTE: &=string;\n%put NOTE: &=file_name_extension;\n%put NOTE: &=compress;\n%put NOTE: &=partition_type;\n%put NOTE: &=partition_by;\n\n* Parse the folder value to get the path;\n%let folderLoc=%scan(&folder,2,\":\");\n%put NOTE: &=folderloc;\n\n%let libname=%upcase(%scan(&inTable,1,\".\"));\n%let memname=%upcase(%scan(&inTable,2,\".\"));\n\n* -----------------------------------------------------------------------------;\n* Delete existing folders / files;\n* -----------------------------------------------------------------------------;\n\nproc python;\nsubmit;\nimport os\nimport shutil\n\n# Get SAS macro variables\nfolderloc = SAS.symget('folderloc')\nmemname = SAS.symget('memname').lower()\npartition_type = SAS.symget('partition_type')\nfile_name_extension = SAS.symget('file_name_extension')\n\nif partition_type in ('DIRECTORY', 'FILENAME', 'HIVE'):\n  # Delete folder-based data\n  fname = f'{folderloc}/{memname}'\n  if os.path.isdir(fname):\n    shutil.rmtree(fname)\n    print(f'Deleted folder {fname}')\nelif partition_type in ('None'):\n  # Delete file-based data\n  fname = f'{folderloc}/{memname}.{file_name_extension}'\n  if os.path.exists(fname):\n    os.remove(fname)\n    print(f'Deleted file {fname}')\n\nendsubmit;\nrun;\n\n* -----------------------------------------------------------------------------;\n* Create export options;\n* -----------------------------------------------------------------------------;\n\n* If SAS characters are to be converted to Parquet STRING logical type;\n%if &string %then %do;\n  * Get count of character columns in SAS dataset;\n  proc sql noprint;\n    select count(*) into: n\n    from dictionary.columns\n    where libname=\"&libname\" and memname=\"&memname\" and type=\"char\";\n  quit;\n  %put NOTE: &=n;\n  \n  * Create data set DBTYPE option syntax to set Parquet logical type to STRING;\n  proc sql noprint;\n    select trim(name)!!\"=string\" into: dbtype separated by \" \"\n    from dictionary.columns\n    where \n      libname=\"&libname\" and \n      memname=\"&memname\" and\n      type=\"char\";\n  quit;\n  %put NOTE: &=dbtype;\n%end;\n%else %do;\n  %let n=0;\n%end;\n\n* Create dataset options for export;\ndata _null_;\n  attrib dsoptions length=$16384;\n  * PARTITION_TYPE and PARTITION_BY options;\n  if \"&partition_type\" ne \"None\" then do;\n    dsoptions=trim(dsoptions)!!\"partition_type=&partition_type\";\n    if \"&partition_by\" ne \"\" then do;\n      dsoptions=trim(dsoptions)!!\" partition_by=(&partition_by)\";\n    end;\n  end;\n  * DBTYPE option;\n  if &string and &n>0 then do;\n    dsoptions=trim(dsoptions)!!\" dbtype=(&dbtype)\";\n  end;\n  * Combine PARTITION_TYPE, PARTITION_BY and DBTYPE options into a;\n  * single dsoptions macro variable;\n  if dsoptions ne \"\" then do;\n    call symput(\"dsoptions\",\"(\"!!trim(left(dsoptions))!!\")\");\n  end;\n  else do;\n    call symput(\"dsoptions\",\" \");\n  end;\nrun;\n%put NOTE: &=dsoptions;\n\n* -----------------------------------------------------------------------------;\n* Export SAS dataset to Parquet;\n* -----------------------------------------------------------------------------;\n\n* Create a temporary libname for the export;\nlibname _pqt_ parquet \"&folderLoc\" compress=&compress file_name_extension=(&file_name_extension);\n%put NOTE: Use this libname syntax to read exported Parquet; %put NOTE: libname mypqt parquet \"&folderLoc\" compress=&compress file_name_extension=(&file_name_extension)%str(;);\n\n* Do the export;\ndata _pqt_.%lowcase(&memname) &dsoptions;\n  set &inTable;\nrun;\n\n* Clear the libname;\nlibname _pqt_ clear;\n\n* -----------------------------------------------------------------------------;\n* Get exported Parquet file's metadata;\n* -----------------------------------------------------------------------------;\n\nproc python;\nsubmit;\n\ntry:\n  import pyarrow.parquet as pq\nexcept:\n  print('NOTE: PyArrow module not available, unable to report Parquet metadata')\nelse:\n  print(f'NOTE: PyArrow version: {pyarrow.__version__}')\n  # Get SAS macro variables\n  folderloc = SAS.symget('folderloc')\n  partition_type = SAS.symget('partition_type')\n  file_name_extension = SAS.symget('file_name_extension')\n  \n  if partition_type in ('DIRECTORY', 'FILENAME', 'HIVE'):\n    fname = f'{folderloc}/{memname}'\n  elif partition_type in ('None'):\n    fname = f'{folderloc}/{memname}.{file_name_extension}'\n  \n  ParquetDataset = pq.ParquetDataset(fname, use_legacy_dataset=False)\n  \n  print('-- Parquet schema:')\n  print(ParquetDataset.schema)\n  \n  print('-- Parquet file(s):')\n  for file in ParquetDataset.files:\n    print(file)\n\nendsubmit;\nrun;\n\n* -----------------------------------------------------------------------------;"}}
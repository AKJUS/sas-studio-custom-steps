{"creationTimeStamp":"2022-11-27T15:43:47.213Z","modifiedTimeStamp":"2022-11-28T20:01:32.079Z","createdBy":"viyademo01","modifiedBy":"viyademo01","name":"Extract Text Features.step","displayName":"Extract Text Features.step","localDisplayName":"Extract Text Features.step","properties":{},"links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","uri":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","uri":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","uri":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","uri":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","uri":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","uri":"/dataFlows/steps/0056394b-ff8c-4d28-975e-6d9f23855120","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":0.0,"version":2,"type":"code","flowMetadata":{"inputPorts":[{"name":"inTable","displayName":"inTable","localDisplayName":"inTable","minEntries":1,"maxEntries":1,"type":"table"},{"name":"custConInTable","displayName":"custConInTable","localDisplayName":"custConInTable","minEntries":0,"maxEntries":1,"type":"table"}],"outputPorts":[{"name":"outTable","displayName":"outTable","localDisplayName":"outTable","description":"Extract Text Features enables you to generate up to hundreds of additional features based on a text column. For the full power of this step to be unlocked you have to have SAS Visual Text Analytics licensed.","localDescription":"Extract Text Features enables you to generate up to hundreds of additional features based on a text column. For the full power of this step to be unlocked you have to have SAS Visual Text Analytics licensed.","minEntries":1,"maxEntries":1,"type":"table","columnDelta":{"automaticMapping":[{"inputPort":"inTable","inputPortName":"inTable"},{"inputPort":"custConInTable","inputPortName":"custConInTable"}]},"requiresStructure":false},{"name":"outTableRexExContext","displayName":"outTableRexExContext","localDisplayName":"outTableRexExContext","minEntries":0,"maxEntries":1,"type":"table","requiresStructure":false}]},"ui":"{\n\t\"showPageContentOnly\": true,\n\t\"pages\": [\n\t\t{\n\t\t\t\"id\": \"page1\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Base Metadata\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"inTable\",\n\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\"label\": \"Input Table containing your Text\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"outTable\",\n\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\"label\": \"Output Table containing the additional Features\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text1\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The step extracts features from your Text.\\n\\nAll variables created start with _etm.\\n\\nThis step only works with SAS Base Engine tables.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textCol\",\n\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\"label\": \"Select the column that contains the Text:\",\n\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\"columntype\": \"c\",\n\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"table\": \"inTable\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createPercentUsed\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to create a percentage of the used available characters?\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"maxCharsAllowed\",\n\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\"label\": \"How many characters are allowed?\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\"visible\": \"$createPercentUsed\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text2\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"For the Extraction of User Mentions, Hashtags and Links there is four stages that build on top of each other:\\n1. A count per Text of the Feature\\n2. A concatenated Column of the Feature per Text\\n3. A separate column for each Feature per Text (this is non-unique, there will be n columns created depending on the most Features found in one Text)\\n4. Create Co-Occurrence column for the top Features\\nYou need to accept the concatenated columns in order to get the ability to have the concatenated values separated in their own columns and to create Co-Occurrences.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section5\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Extract User Mentions\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createUserMentions\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to extract a Count of User Mentions (@)?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"concatAtSigns\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concatenated Column of all User Mentions per Text?\",\n\t\t\t\t\t\t\t\"visible\": \"$createUserMentions\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleAtSigns\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create separated columns for User Mentions?\",\n\t\t\t\t\t\t\t\"visible\": \"$concatAtSigns\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createAtOccurences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create Co-Occurrences for User Mentions?\",\n\t\t\t\t\t\t\t\"visible\": \"$singleAtSigns\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfAtOccurences\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Times a User has to be mentioned to be counted as a significant Co-Occurrence\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createAtOccurences\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfAtOutputs\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Limit the number of Co-Occurrences for User Mentions to the Top (highly suggested to reduce dataset size):\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createAtOccurences\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section1\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Extract Hashtags\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createHashtags\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to extract a Count of Hashtags (#)?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"concatHashtags\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concatenated Column of all Hashtags per Text?\",\n\t\t\t\t\t\t\t\"visible\": \"$createHashtags\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleHashtags\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create separated columns for Hashtags?\",\n\t\t\t\t\t\t\t\"visible\": \"$concatHashtags\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createHTOccurences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create Co-Occurrences for Hashtags?\",\n\t\t\t\t\t\t\t\"visible\": \"$singleHashtags\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfHTOccurences\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Times a Hashtags has to be mentioned to be counted as a significant Co-Occurrence\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createHTOccurences\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfHTOutputs\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Limit the number of Co-Occurrences for Hashtags to the Top (highly suggested to reduce dataset size):\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createHTOccurences\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section6\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Extract Links\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text7\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Please note that for the Link Data page options to unlock you have to create a concatenated column and separated columns for the links here.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createLinks\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to extract a Count of Links (http)?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"concatLinks\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concatenated Column of all Links per Text?\",\n\t\t\t\t\t\t\t\"visible\": \"$createLinks\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleLinks\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create separated columns for Links?\",\n\t\t\t\t\t\t\t\"visible\": \"$concatLinks\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createLKOccurences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create Co-Occurrences for Links?\",\n\t\t\t\t\t\t\t\"visible\": \"$singleLinks\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfLKOccurences\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Times a Links has to be mentioned to be counted as a significant Co-Occurrence\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createLKOccurences\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numOfLKOutputs\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Limit the number of Co-Occurrences for Links Mentions to the Top (highly suggested to reduce dataset size):\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createLKOccurences\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page5\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Custom RegEx Pattern\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text8\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"This page enables you to extract your own custom feature based on a RegEx pattern.\\n\\nPlease ensure that you enter a valid RegEx pattern. You can use the SAS data step function prxparse to check the validity of your pattern.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"extractCustomRegEx\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to extract a custom RegEx Pattern from the text?\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"prxPattern\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"Please enter a valid RegEx pattern here - you have to enclose it in / and you can specify a RegEx Flag:\",\n\t\t\t\t\t\"placeholder\": \"/test/i\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"minDocCnt\",\n\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\"label\": \"Only create a Feature if the Pattern occurs n times:\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createCustomRegExGraphics\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Add Tables summarizing the findings to the Results\",\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section9\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Snippet Context Window for the Pattern (Optional)\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text10\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Enables you to create an additional output table the contains next to the extracted pattern some surrounding text to better enable you to judge if your pattern worked as you intended.\\n\\nTo enter a custom name for this table please right click the step in the flow > Expand Output Ports and then connect your desired output table to the new port.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createSnippetTable\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create an additional table containing some context around the found RegEx Pattern?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"snipplet_window\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of characters extracte before and after the Occurrence:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$createSnippetTable\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"outTableRexExContext\",\n\t\t\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\t\t\"label\": \"RegEx Context Table Output\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"work._etm_regex_context\",\n\t\t\t\t\t\t\t\"visible\": \"$createSnippetTable\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section8\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Feature Association with Target (Optional)\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$extractCustomRegEx\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text9\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"If you have a numerical binary target variable with values 0 and 1 then you can create additional statistics to show the association of the target level with the feature.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"regExTargetCheck\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you have a binary numeric Target variable?\",\n\t\t\t\t\t\t\t\"visible\": \"$extractCustomRegEx\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"regExTarget\",\n\t\t\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\t\t\"label\": \"Please select the Target variable from the Input Data Set:\",\n\t\t\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\t\t\"columntype\": \"n\",\n\t\t\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$regExTargetCheck\",\n\t\t\t\t\t\t\t\"table\": \"inTable\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"minTgMean\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Minimum Target Mean:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": false,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 10,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$regExTargetCheck\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxTgMean\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Maximum Target Mean\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 10,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": \"$regExTargetCheck\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page3\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Link Data\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text4\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"Collect additional information from the links in the tweets. This option requires you to have enabled the Options for concatenated and separated columns.\\n\\nPlease note for this step to work your environment needs to be able to make calls to the open internet and the following Python packages need to be available:\\n- pandas\\n- requests\\n- bs4\\n\\nPlease be also aware that this step can take a lot of time to run as the individual sites have to be called and their output need to be parsed.\\n\\nThe following five features are extracted for each link:\\n- HTTP Status Code (basically is it reachable or not)\\n- Title of the Webpage\\n- Description of the Webpage\\n- URL of the Webpage (handy if URL shorteners were used\\n- Owner of the site\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"getLinkMetadata\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to collect metadata from Links in the text?\",\n\t\t\t\t\t\"visible\": \"$singleLinks\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"allowUnverifiedRequests\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to allow Unverified Requests (Warning potential impact: Breach of Confidentiality & Breach of Integrity)?\",\n\t\t\t\t\t\"visible\": \"$getLinkMetadata\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"urlLimiter\",\n\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\"label\": \"Limit the number of Links to the Top:\",\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\"visible\": \"$getLinkMetadata\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page4\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Text Analytics - Start\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text5\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The additional information derived here is only available if you have SAS Visual Text Analytics licensed.\\n\\nTo detect the sentiment and extract text topics you have to select the language detection option.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"useTextAnalytics\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to use Text Analytics? (license required)\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"howLanguage\",\n\t\t\t\t\t\"type\": \"radiogroup\",\n\t\t\t\t\t\"label\": \"Do you want to automatically detect the text language?\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"1\",\n\t\t\t\t\t\t\t\"label\": \"Yes\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"0\",\n\t\t\t\t\t\t\t\"label\": \"No\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"userSpecifiedLanguage\",\n\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\"label\": \"Please select the language of your text:\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ar\",\n\t\t\t\t\t\t\t\"label\": \"Arabic\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"zh\",\n\t\t\t\t\t\t\t\"label\": \"Chinese\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"hr\",\n\t\t\t\t\t\t\t\"label\": \"Croatian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"cs\",\n\t\t\t\t\t\t\t\"label\": \"Czech\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"da\",\n\t\t\t\t\t\t\t\"label\": \"Danish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"nl\",\n\t\t\t\t\t\t\t\"label\": \"Dutch\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"en\",\n\t\t\t\t\t\t\t\"label\": \"English\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"fi\",\n\t\t\t\t\t\t\t\"label\": \"Finnish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"fr\",\n\t\t\t\t\t\t\t\"label\": \"French\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"de\",\n\t\t\t\t\t\t\t\"label\": \"German\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"el\",\n\t\t\t\t\t\t\t\"label\": \"Greek\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"iw\",\n\t\t\t\t\t\t\t\"label\": \"Hebrew\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"hi\",\n\t\t\t\t\t\t\t\"label\": \"Hindi\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"hu\",\n\t\t\t\t\t\t\t\"label\": \"Hungarian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"in\",\n\t\t\t\t\t\t\t\"label\": \"Indonesian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"it\",\n\t\t\t\t\t\t\t\"label\": \"Italian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ja\",\n\t\t\t\t\t\t\t\"label\": \"Japanese\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"kk\",\n\t\t\t\t\t\t\t\"label\": \"Kazakh\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ko\",\n\t\t\t\t\t\t\t\"label\": \"Korean\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"no\",\n\t\t\t\t\t\t\t\"label\": \"Norwegian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"fa\",\n\t\t\t\t\t\t\t\"label\": \"Persian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"pl\",\n\t\t\t\t\t\t\t\"label\": \"Polish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"pt\",\n\t\t\t\t\t\t\t\"label\": \"Portuguese\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ro\",\n\t\t\t\t\t\t\t\"label\": \"Romanian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ru\",\n\t\t\t\t\t\t\t\"label\": \"Russian\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"sk\",\n\t\t\t\t\t\t\t\"label\": \"Slovak\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"sl\",\n\t\t\t\t\t\t\t\"label\": \"Slovene\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"es\",\n\t\t\t\t\t\t\t\"label\": \"Spanish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"sv\",\n\t\t\t\t\t\t\t\"label\": \"Swedish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"tl\",\n\t\t\t\t\t\t\t\"label\": \"Tagalog\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"th\",\n\t\t\t\t\t\t\t\"label\": \"Thai\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"tr\",\n\t\t\t\t\t\t\t\"label\": \"Turkish\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"vi\",\n\t\t\t\t\t\t\t\"label\": \"Vietnamese\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\"$useTextAnalytics\",\n\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\"$howLanguage\",\n\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\"0\"\n\t\t\t\t\t\t]\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createLanguagePlot\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Create Plot of Detected Languages\",\n\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\"$howLanguage\",\n\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\"1\"\n\t\t\t\t\t\t],\n\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\"$useTextAnalytics\"\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section7\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Text Profiling\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"profileText\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to profile your text?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"compareReferenceCorpus\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Compare your text corpus to reference corpus profiles (Not available for all languages yet, raises a warning accordingly)\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createProfileTextGraphs\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Add Word and Sentence count per Document and Language to the Results\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createNumSentences\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create a feature for the number of sentences in the Text\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createMaxTokenSentence\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create a feature for the count of tokens in the longest sentence\",\n\t\t\t\t\t\t\t\"visible\": \"$profileText\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section2\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Sentiment detection\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"detectSentiment\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to detect the text sentiment?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createSentimentPlot\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Plot of Sentiment by Languages\",\n\t\t\t\t\t\t\t\"visible\": \"$detectSentiment\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section4\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Text Concept Extraction\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text13\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Selecting SAS Predefined Concepts also enables you to use these as features in the customization options for the Text Topic Creation.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createPredefinedConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to apply the SAS Predefined Concepts?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"conceptList\",\n\t\t\t\t\t\t\t\"type\": \"list\",\n\t\t\t\t\t\t\t\"label\": \"Select Predefined Concepts you wish applied to your text:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpDate\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Date\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpMeasure\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Measure\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpMoney\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Money\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpNounGroup\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Noun Group\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpOrganization\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Organization\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpPercent\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Percent\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpPerson\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Person\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpPlace\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Place\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"nlpTime\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Time\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"max\": 9,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"visible\": \"$createPredefinedConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createPreConceptPlot\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Plot of Extracted SAS Predefined Concepts for each Language\",\n\t\t\t\t\t\t\t\"visible\": \"$createPredefinedConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createConcatedPreConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concated column of all matched text for each pre defined concept type?\",\n\t\t\t\t\t\t\t\"visible\": \"$createPredefinedConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singlePreConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want SAS Pre Defined Concepts as seperated columns?\",\n\t\t\t\t\t\t\t\"visible\": \"$createConcatedPreConcepts\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section10\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Custom Text Concept Extraction\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text11\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Please ensure that you have validated your Custom Concepts before using this step.\\n\\nTo add the table containing your Custom Concepts right click the step in the flow > Expand Input Ports and then connect your desired input table to the new port.\\n\\nSupplying your own Custom Concepts also enables you to use these features in the customization options for the Text Topic Creation.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"useCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to apply custom concepts?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"custConInTable\",\n\t\t\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\t\t\"label\": \"Please add an input table containg your Custom Concepts\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"work.custom_concepts\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"compiledCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Are your concepts already compiled?\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"customConInTable\",\n\t\t\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\t\t\"label\": \"Please select the column containing the custom concept\",\n\t\t\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\t\t\"columntype\": \"c\",\n\t\t\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\",\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\"!$compiledCustomConcepts\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"table\": \"custConInTable\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createCustomConceptPlot\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Plot of Extracted Custom Concepts for each Language\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createConcatedCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to create a concated column of all matched text for each Custom Concept?\",\n\t\t\t\t\t\t\t\"visible\": \"$useCustomConcepts\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"singleCustomConcepts\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want Custom Concepts as seperated columns?\",\n\t\t\t\t\t\t\t\"visible\": \"$createConcatedCustomConcepts\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page6\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Text Analytics - Topic Creation\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text12\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The additional information derived here is only available if you have SAS Visual Text Analytics licensed.\\n\\nTopics are created for all languages that have more 50 or more rows in the dataset.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createTopics\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to have Topics created for you?\",\n\t\t\t\t\t\"visible\": \"$useTextAnalytics\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"useBestPractise\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want us the Text Topic Creation Best Practise?\",\n\t\t\t\t\t\"visible\": \"$createTopics\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section3\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Parse Text\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"!$useBestPractise\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"posTagging\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Include Parts of Speech\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"extractNounGroups\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Extract Noun Groups\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"extractEntities\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Extract Entities\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"stemTerms\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Stem Terms\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"minOccKeep\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Minimum number of occurrences to keep a term:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"cellWeight\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Use the log to weight the cells of the term-by-document matrix\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"termWeight\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Weight terms by:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"entropy\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Entropy\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"mi\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Mutual Information\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"none\",\n\t\t\t\t\t\t\t\t\t\"label\": \"No weighting\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"useStopWords\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Do you want to use a stop word list?\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"normProjects\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Normalize the Document Projections, Term Projections, or Both:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"all\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Both\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"doc\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Document\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"word\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Word\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"none\",\n\t\t\t\t\t\t\t\t\t\"label\": \"None\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section12\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Discover Topics\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"!$useBestPractise\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numTopics\",\n\t\t\t\t\t\t\t\"type\": \"radiogroup\",\n\t\t\t\t\t\t\t\"label\": \"How to discover Topics:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"0\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Specify number of Topics\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"1\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Recommend number of topics\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numTopicsK\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of topics:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 1000,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$numTopics\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"0\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numTopicsMaxK\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Maximum number of topics:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 1000,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$numTopics\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"1\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"resolutionLevel\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Desired Resolution Level for the recommended Number of Dimensions to be extracted by the SVD:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"low\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Low\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"med\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Medium\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"high\",\n\t\t\t\t\t\t\t\t\t\"label\": \"High\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"rotationType\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Type of Rotation used to Maximize the Explanatory Power of each Topic\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"varimax\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Uncorrelated Topics (Varimax)\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"promax\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Correlated Topics (Promax)\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"numLabels\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of Terms to use in the Descriptive Label for each Topic\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 500,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"selectEntities\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"List of Entity Types to be kept - All of the SAS Predefined Concepts and Custom Concepts that you included will be used if selected\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$createPredefinedConcepts\",\n\t\t\t\t\t\t\t\t\"|\",\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"defaultEntityPrio\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Set the Default Entity Priority:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\"max\": 31,\n\t\t\t\t\t\t\t\"stepsize\": 1,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$selectEntities\",\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"hasCustomPrio\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Does your table containg the compiled Custom Concepts contain a column named _priority_? If not a the priority is calculated as Defaulit Entity Priority + 1.\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$selectEntities\",\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\"$useCustomConcepts\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section11\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Plots\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"$createTopics\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"createScreePlotSVD\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Create Scree Plots of the SVD for each language\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page7\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Text Analytics - Bool Rule Creation\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text6\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The additional information derived here is only available if you have SAS Visual Text Analytics licensed.\\n\\nPlease note that BoolRule creation can have significant target leakage, but it can be generate powerful features. Often times it is useful to check the created rules and abstract them into custom concepts or a RegEx pattern.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"createBoolRules\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want to leverage BoolRule Creation to create additional Features?\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"useTopicCreationTbD\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Do you want use the Term-by-Document Matrix from the Topic Creation?\",\n\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\"$createTopics\",\n\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\"$createBoolRules\"\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"boolRuleTarget\",\n\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\"label\": \"Please select a target variable:\",\n\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\"columntype\": \"a\",\n\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\"visible\": \"$createBoolRules\",\n\t\t\t\t\t\"table\": \"inTable\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"boolRuleTargetType\",\n\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\"label\": \"Please select the Type of your Target Variable:\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"Binary\",\n\t\t\t\t\t\t\t\"label\": \"Binary\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"Multiclass\",\n\t\t\t\t\t\t\t\"label\": \"Multiclass\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"Multilabel\",\n\t\t\t\t\t\t\t\"label\": \"Multilabel\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"$createBoolRules\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"section13\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Customization\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"$createBoolRules\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"gPosBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Minimum G-Score needed for a Positive Term to be considered for Rule Extraction:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"mPosBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the M Value for computing Estimated Precision for Positive Terms:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"gNegBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Minimum G-Score needed for a Negative Term to be considered for Rule Extraction:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"mNegBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the M Value for computing Estimated Precision for Negative Terms:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"minSupportsBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Minimum Number of Documents in which a Term needs to appear in order for the Term to be used for creating a Rule:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxCandidatesBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the Number of Term Candidates to be selected for each Category:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxTriesInBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the K-In Value for K-Best Search in the Term Ensemble Process for Creating Rules:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"maxTriesOutBR\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Enter the K-Out Value for K-Best Search in the Term Ensemble Process for Creating Rules:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 32767,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"page2\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"About\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"text3\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"The output always contains the following for each Text:\\n- Number of Full Stops\\n- Number of Questions Marks\\n- Number of Exclamation Points\\n- Number of User Mentions\\n- Number of Hashtags\\n- Number of Links\\n- Total Word Count\\n- Total Character Count\\n\\nIf you use the of the Additional Metadata or Text Analytics features a unique ID is generated for your text called _etm_ID.\\n\\nFor more information about the algorithms and parameters please take a look at the SAS documentation site: https://documentation.sas.com/?cdcId=pgmsascdc&cdcVersion=default&docsetId=casvtapg&docsetTarget=n1tlj0l2pvf92vn1ruide9yikmlo.htm\\n\\nThis custom step was created in collaboration between:\\n- David.Weik@sas.com\\n- Ulrich.Reincke@sas.com\\n- Rens.Feenstra@sas.com\\n\\nVersion 1.0 (27NOV2022)\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t],\n\t\"syntaxversion\": \"1.3.0\",\n\t\"values\": {\n\t\t\"inTable\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"outTable\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"textCol\": [],\n\t\t\"createPercentUsed\": true,\n\t\t\"maxCharsAllowed\": 240,\n\t\t\"createUserMentions\": true,\n\t\t\"concatAtSigns\": true,\n\t\t\"singleAtSigns\": true,\n\t\t\"createAtOccurences\": true,\n\t\t\"numOfAtOccurences\": 5,\n\t\t\"numOfAtOutputs\": 25,\n\t\t\"createHashtags\": true,\n\t\t\"concatHashtags\": true,\n\t\t\"singleHashtags\": true,\n\t\t\"createHTOccurences\": true,\n\t\t\"numOfHTOccurences\": 5,\n\t\t\"numOfHTOutputs\": 25,\n\t\t\"createLinks\": true,\n\t\t\"concatLinks\": true,\n\t\t\"singleLinks\": true,\n\t\t\"createLKOccurences\": true,\n\t\t\"numOfLKOccurences\": 5,\n\t\t\"numOfLKOutputs\": 25,\n\t\t\"extractCustomRegEx\": false,\n\t\t\"prxPattern\": \"\",\n\t\t\"minDocCnt\": 10,\n\t\t\"createCustomRegExGraphics\": true,\n\t\t\"createSnippetTable\": false,\n\t\t\"snipplet_window\": 10,\n\t\t\"outTableRexExContext\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"regExTargetCheck\": false,\n\t\t\"regExTarget\": [],\n\t\t\"minTgMean\": 7,\n\t\t\"maxTgMean\": 3,\n\t\t\"getLinkMetadata\": false,\n\t\t\"allowUnverifiedRequests\": false,\n\t\t\"urlLimiter\": 10,\n\t\t\"useTextAnalytics\": false,\n\t\t\"howLanguage\": {\n\t\t\t\"value\": \"1\",\n\t\t\t\"label\": \"Yes\"\n\t\t},\n\t\t\"userSpecifiedLanguage\": null,\n\t\t\"createLanguagePlot\": true,\n\t\t\"profileText\": false,\n\t\t\"compareReferenceCorpus\": false,\n\t\t\"createProfileTextGraphs\": true,\n\t\t\"createNumSentences\": false,\n\t\t\"createMaxTokenSentence\": false,\n\t\t\"detectSentiment\": false,\n\t\t\"createSentimentPlot\": true,\n\t\t\"createPredefinedConcepts\": false,\n\t\t\"conceptList\": [\n\t\t\t{\n\t\t\t\t\"value\": \"nlpDate\",\n\t\t\t\t\"label\": \"Date\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpMeasure\",\n\t\t\t\t\"label\": \"Measure\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpMoney\",\n\t\t\t\t\"label\": \"Money\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpNounGroup\",\n\t\t\t\t\"label\": \"Noun Group\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpOrganization\",\n\t\t\t\t\"label\": \"Organization\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpPercent\",\n\t\t\t\t\"label\": \"Percent\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpPerson\",\n\t\t\t\t\"label\": \"Person\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpPlace\",\n\t\t\t\t\"label\": \"Place\"\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"value\": \"nlpTime\",\n\t\t\t\t\"label\": \"Time\"\n\t\t\t}\n\t\t],\n\t\t\"createPreConceptPlot\": true,\n\t\t\"createConcatedPreConcepts\": false,\n\t\t\"singlePreConcepts\": false,\n\t\t\"useCustomConcepts\": false,\n\t\t\"custConInTable\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"compiledCustomConcepts\": false,\n\t\t\"customConInTable\": [],\n\t\t\"createCustomConceptPlot\": true,\n\t\t\"createConcatedCustomConcepts\": false,\n\t\t\"singleCustomConcepts\": false,\n\t\t\"createTopics\": false,\n\t\t\"useBestPractise\": true,\n\t\t\"posTagging\": true,\n\t\t\"extractNounGroups\": true,\n\t\t\"extractEntities\": true,\n\t\t\"stemTerms\": true,\n\t\t\"minOccKeep\": 10,\n\t\t\"cellWeight\": true,\n\t\t\"termWeight\": {\n\t\t\t\"value\": \"entropy\",\n\t\t\t\"label\": \"Entropy\"\n\t\t},\n\t\t\"useStopWords\": true,\n\t\t\"normProjects\": {\n\t\t\t\"value\": \"all\",\n\t\t\t\"label\": \"Both\"\n\t\t},\n\t\t\"numTopics\": {\n\t\t\t\"value\": \"1\",\n\t\t\t\"label\": \"Recommend number of topics\"\n\t\t},\n\t\t\"numTopicsK\": 25,\n\t\t\"numTopicsMaxK\": 25,\n\t\t\"resolutionLevel\": {\n\t\t\t\"value\": \"high\",\n\t\t\t\"label\": \"High\"\n\t\t},\n\t\t\"rotationType\": {\n\t\t\t\"value\": \"varimax\",\n\t\t\t\"label\": \"Uncorrelated Topics (Varimax)\"\n\t\t},\n\t\t\"numLabels\": 5,\n\t\t\"selectEntities\": false,\n\t\t\"defaultEntityPrio\": 0,\n\t\t\"hasCustomPrio\": false,\n\t\t\"createScreePlotSVD\": true,\n\t\t\"createBoolRules\": false,\n\t\t\"useTopicCreationTbD\": false,\n\t\t\"boolRuleTarget\": [],\n\t\t\"boolRuleTargetType\": {\n\t\t\t\"value\": \"Binary\",\n\t\t\t\"label\": \"Binary\"\n\t\t},\n\t\t\"gPosBR\": 10,\n\t\t\"mPosBR\": 10,\n\t\t\"gNegBR\": 10,\n\t\t\"mNegBR\": 10,\n\t\t\"minSupportsBR\": 10,\n\t\t\"maxCandidatesBR\": 10,\n\t\t\"maxTriesInBR\": 10,\n\t\t\"maxTriesOutBR\": 10\n\t}\n}","templates":{"SAS":"* _etm is short for extract text metadata;\n\n%macro _etm_create_base_metadata;\n    * Count different metadata contained in the text;\n    * And concatenating user mentions, hashtags and links;\n    data &outTable.;\n        set &inTable.;\n    \n        %if &concatAtSigns. or &concatHashtags. or &concatLinks. or &useTextAnalytics. %then %do;\n            length _etm_ID 8.;\n            label _etm_ID = 'Unqiue Document ID';\n            \n            _etm_ID = _N_;\n        %end;\n    \n        length _etm_N_FullStop _etm_N_Quest _etm_N_Exclam \n            _etm_wrd_cnt _etm_chrctr_cnt _etm_i 8.;\n\n        %if &createPercentUsed. %then %do;\n            length _etm_prcntUsd 8.;\n            label _etm_prcntUsd = 'Percentage used of the maximum allowed characters';\n        %end;\n\n        %if &createUserMentions. %then %do;\n            length _etm_N_AtSigns 8.;\n            label _etm_at_term = 'All User mentions in the text concatenated';\n            _etm_N_AtSigns = count(&textCol_1_name_base.,'@');\n        %end;\n        %if &createHashtags. %then %do;\n            length _etm_N_HashTags 8.;\n            label _etm_hshtg_term = 'All Hashtags in the text concatenated';\n            _etm_N_HashTags = count(&textCol_1_name_base.,'#');\n        %end;\n        %if &createLinks. %then %do;\n            length _etm_N_Links  8.;\n            label _etm_lnks_term = 'All links in the text concatenated';\n            _etm_N_Links = count(&textCol_1_name_base.,'http');\n        %end;\n    \n        length _etm_tmp_at_term _etm_tmp_hshtg_term _etm_tmp_lnks_term \n            _etm_at_term _etm_hshtg_term _etm_lnks_term $&textCol_1_rawlength.;\n    \n        label _etm_N_FullStop = 'Number of Periods in the Text'\n            _etm_N_Quest = 'Number of Question Marks in the Text'\n            _etm_N_Exclam = 'Number of Exclamations Points in the Text'\n            _etm_N_AtSigns = 'Number of At Signs in the Text'\n            _etm_N_HashTags = 'Number of Hashtags in the Text'\n            _etm_N_Links = 'Number of Links in the Text'\n            _etm_wrd_cnt = 'Number of Words in a Text'\n            _etm_chrctr_cnt = 'Number of Characters in a Text';\n    \n        _etm_N_FullStop = count(&textCol_1_name_base.,'.');\n        _etm_N_Quest = count(&textCol_1_name_base.,'?');\n        _etm_N_Exclam = count(&textCol_1_name_base.,'!');\n        _etm_wrd_cnt = countw(strip(&textCol_1_name_base.), ' ');\n        _etm_chrctr_cnt = length(&textCol_1_name_base.);\n    \n        %if &createPercentUsed. %then %do;\n            _etm_prcntUsd = _etm_chrctr_cnt / &maxCharsAllowed.;\n        %end;\n    \n        * Create concataned Values;\n        %if &concatAtSigns. or &concatHashtags. or &concatLinks. %then %do;\n            length _etm_tmp_at_term _etm_tmp_hshtg_term _etm_tmp_lnks_term $&textCol_1_rawlength.;\n\n            if _etm_N_AtSigns > 0 or _etm_N_HashTags > 0 or _etm_N_Links > 0 then do;\n                _etm_i = 1;\n                do while(_etm_i <= _etm_wrd_cnt);\n    \n                    * Search for User mentions;\n                    %if &concatAtSigns. %then %do;\n                        length _etm_at_term $&textCol_1_rawlength.;\n                        label _etm_at_term = 'Concatenated List of all User Mentions in the Text';                        \n\n                        if _etm_N_AtSigns > 0 then do;\n                            _etm_tmp_at_term = scan(strip(&textCol_1_name_base.), _etm_i);\n                            if substr(_etm_tmp_at_term, 1, 1) = '@' then do;\n                                _etm_tmp_at_term = lowcase(strip(_etm_tmp_at_term));\n                                _etm_at_term = strip(_etm_at_term) || ' ' || substr(_etm_tmp_at_term, 2);\n                            end;\n                        end;\n                    %end;\n\n                    * Search for Hashtags;\n                    %if &concatHashtags. %then %do;\n                        length _etm_hshtg_term $&textCol_1_rawlength.;\n                        label _etm_hshtg_term = 'Concatenated List of all Hashtags in the Text';\n\n                        if _etm_N_HashTags > 0 then do;\n                            _etm_tmp_hshtg_term = scan(strip(&textCol_1_name_base.), _etm_i);\n                            if substr(_etm_tmp_hshtg_term, 1, 1) = '#' then do;\n                                _etm_tmp_hshtg_term = lowcase(strip(_etm_tmp_hshtg_term));\n                                _etm_hshtg_term = strip(_etm_hshtg_term) || ' ' || substr(_etm_tmp_hshtg_term, 2);\n                            end;\n                        end;\n                    %end;\n    \n                    * Search for Links;\n                    %if &concatLinks. %then %do;\n                        length _etm_lnks_term $&textCol_1_rawlength.;\n                        label _etm_lnks_term = 'Concatenated List of all Links in the Text';\n\n                        if _etm_N_Links > 0 then do;\n                            _etm_tmp_lnks_term = scan(strip(&textCol_1_name_base.), _etm_i, ' ');\n                            if substr(_etm_tmp_lnks_term, 1, 4) = 'http' then do;\n                                _etm_lnks_term = strip(_etm_lnks_term) || ' ' || strip(_etm_tmp_lnks_term);\n                            end;\n                        end;\n                    %end;\n    \n                    _etm_i + 1;\n                end;\n            end;\n\n            drop _etm_i _etm_tmp_at_term _etm_tmp_hshtg_term _etm_tmp_lnks_term;\n        %end;\n    run;\n%mend _etm_create_base_metadata;\n\n%_etm_create_base_metadata;\n\n* Remove the macro;\nproc catalog cat=work.sasmacr;\n    delete _etm_create_base_metadata.macro;\nrun;\n\n* Check if the users wants the concatenated values as seperated columns;\n%if &singleAtSigns. or &singleHashtags. or &singleLinks. %then %do;\n    * Get the max number of outputs;\n    proc sql noprint;\n        select max(_etm_N_AtSigns) into :_etm_max_AtSign\n                from &outTable.;\n    \n        select max(_etm_N_HashTags) into :_etm_max_HashTags\n                from &outTable.;\n    \n        select max(_etm_N_Links) into :_etm_max_Links\n                from &outTable.;\n    run;\n\n    %macro _etm_create_individual_cols;\n        data &outTable.;\n            set &outTable.;\n\n            * Separated Columns for User Mentions;\n            %if &singleAtSigns. %then %do;\n                %do i=1 %to &_etm_max_AtSign.;\n                    length _etm_AtSign_&i. $&textCol_1_rawlength.;\n                    label _etm_AtSign_&i. = \"&i.. user mention in the text\";\n                    _etm_AtSign_&i. = scan(_etm_at_term, &i.);\n                %end;\n            %end;\n\n            * Separated Columns for Hashtags;\n            %if &singleHashtags. %then %do;\n                %do i=1 %to &_etm_max_HashTags.;\n                    length _etm_HashTags_&i. $&textCol_1_rawlength.;\n                    label _etm_HashTags_&i. = \"&i.. hashtag in the text\";\n                    _etm_HashTags_&i. = scan(_etm_hshtg_term, &i.);\n                %end;\n            %end;\n\n            * Separated Columns for User Links;\n            %if &singleLinks. %then %do;\n                %do i=1 %to &_etm_max_Links.;\n                    length _etm_lnks_&i. $&textCol_1_rawlength.;\n                    label _etm_lnks_&i. = \"&i.. link in the text\";\n                    _etm_lnks_&i. = scan(_etm_lnks_term, &i., ' ');\n                %end;\n            %end;\n        run;\n    %mend _etm_create_individual_cols;\n\n    %_etm_create_individual_cols;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n       delete _etm_create_individual_cols.macro;\n    run;\n\n    * Remove macro variables, that where created in the step;\n    %symdel _etm_max_AtSign _etm_max_HashTags _etm_max_Links;\n%end;\n\n\n* Check if the users wants Co-Occurences to be added;\n%if &createAtOccurences. or &createHTOccurences. or &createLKOccurences. %then %do;\n    * Add a binary field on Co-Occurence 0 = No and 1 = Yes;\n    %macro _etm_cooccurence;\n        * Create a table containing a row per value and id;\n        data %if &createAtOccurences. %then work._etm_all_mentions(keep=_etm_ID _etm_tmp_at_term);\n            %if &createHTOccurences. %then work._etm_all_hashtags(keep=_etm_ID _etm_tmp_hshtg_term);\n            %if &createLKOccurences. %then work._etm_all_links(keep=_etm_ID _etm_tmp_lnks_term);\n            ;\n        \n            length %if &createAtOccurences. %then _etm_tmp_at_term;\n                %if &createHTOccurences. %then _etm_tmp_hshtg_term;\n                %if &createLKOccurences. %then _etm_tmp_lnks_term;\n                 $&textCol_1_rawlength.;\n\n            set &outTable.;\n        \n            * User Mentions;\n            %if &createAtOccurences. %then %do;\n                _etm_i = 1;\n                if _etm_N_AtSigns > 0 then do;\n                    do until(_etm_i <= _etm_N_AtSigns);\n                        _etm_tmp_at_term = scan(_etm_at_term, _etm_i);\n                        output work._etm_all_mentions;\n                    end;\n                end;\n            %end;\n        \n            * HashTags;\n            %if &createHTOccurences %then %do;\n                _etm_i = 1;\n                if _etm_N_HashTags > 0 then do;\n                    do until(_etm_i <= _etm_N_HashTags);\n                        _etm_tmp_hshtg_term = scan(_etm_hshtg_term, _etm_i);\n                        output work._etm_all_hashtags;\n                    end;\n                end;\n            %end;\n        \n            * Links;\n            %if &createLKOccurences. %then %do;\n                _etm_i = 1;\n                if _etm_N_Links > 0 then do;\n                    do until(_etm_i <= _etm_N_Links);\n                        _etm_tmp_lnks_term = scan(_etm_lnks_term, _etm_i, ' ');\n                        output work._etm_all_links;\n                    end;\n                end;\n            %end;\n        run;\n        \n        * Create a count per mention, hashtag and link;\n            proc sql noprint;\n        %if &createAtOccurences. %then %do;\n            proc sql noprint;\n                create table work._etm_all_mentions_grp as\n                    select count(*) as count_texts, _etm_tmp_at_term\n                        from work._etm_all_mentions\n                            group by _etm_tmp_at_term\n                                having count_texts > &numOfAtOccurences.\n                                    order by count_texts desc;\n            run;\n\n            proc sql noprint;\n                select _etm_tmp_at_term into :_etm_tmp_at_term separated by '|'\n                    from work._etm_all_mentions_grp(obs=&numOfAtOutputs.);\n            run;\n        \n            data &outTable.;\n                set &outTable.;\n                %do i= 1 %to &sqlobs.;\n                     _etm_cooc_At_&i=(strip(_etm_at_term) eq \"%scan(&_etm_tmp_at_term.,&i.,'|')\");\n                     Label _etm_cooc_At_&i.=\"Co-Occurence At_&i.: %scan(&_etm_tmp_at_term.,&i.,'|')\";\n                %end;\n            run;\n\n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_all_mentions _etm_all_mentions_grp;\n            run;\n        %end;\n\n        %if &createHTOccurences. %then %do;\n            proc sql noprint;\n                create table work._etm_all_hashtags_grp as\n                    select count(*) as count_texts, _etm_tmp_hshtg_term\n                        from work._etm_all_hashtags\n                            group by _etm_tmp_hshtg_term\n                                having count_texts > &numOfHTOccurences.\n                                    order by count_texts desc;\n            run;\n\n            proc sql noprint;\n                select _etm_tmp_hshtg_term into :_etm_tmp_hshtg_term separated by '|'\n                    from work._etm_all_hashtags_grp(obs=&numOfHTOutputs.);\n            run;\n        \n            data &outTable.;\n                set &outTable.;\n                %do i= 1 %to &sqlobs.;\n                     _etm_cooc_HashTag_&i=(strip(_etm_hshtg_term) eq \"%scan(&_etm_tmp_hshtg_term.,&i.,'|')\");\n                     Label _etm_cooc_HashTag_&i.=\"Co-Occurence HashTag_&i.: %scan(&_etm_tmp_hshtg_term.,&i.,'|')\";\n                %end;\n            run;\n\n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_all_hashtags _etm_all_hashtags_grp;\n            run;\n        %end;\n        %if &createLKOccurences. %then %do;\n            proc sql noprint;\n                create table work._etm_all_links_grp as\n                    select count(*) as count_texts, _etm_tmp_lnks_term\n                        from work._etm_all_links\n                            group by _etm_tmp_lnks_term\n                                having count_texts > &numOfLKOccurences.\n                                    order by count_texts desc;\n            run;\n\n            proc sql noprint;\n                select _etm_tmp_lnks_term into :_etm_tmp_lnks_term separated by '|'\n                    from work._etm_all_links_grp(obs=&numOfLKOutputs.);\n            run;\n        \n            data &outTable.;\n                set &outTable.;\n                %do i= 1 %to &sqlobs.;\n                     _etm_cooc_Link_&i=(strip(_etm_lnks_term) eq \"%scan(&_etm_tmp_lnks_term.,&i.,'|')\");\n                     Label _etm_cooc_Link_&i.=\"Co-Occurence Link_&i.: %scan(&_etm_tmp_lnks_term.,&i.,'|')\";\n                %end;\n            run;\n\n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_all_links _etm_all_links_grp;\n            run;\n        %end;\n    \n    %mend _etm_cooccurence;\n\n    %_etm_cooccurence;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n       delete _etm_cooccurence.macro;\n    run;\n%end;\n\n* Extract a user specified RegEx Pattern as additional features;\n%if &extractCustomRegEx. %then %do;\n\n    %macro _etm_regex_extraction;\n        %let _etm_len_snip=%sysevalf(&textCol_1_rawlength.+2*&snipplet_window.);\n        \n        %if &regExTargetCheck. %then %do;\n            %let minTgMean = %sysevalf(&minTgMean. / 10);\n            %let maxTgMean = %sysevalf(&maxTgMean. / 10);\n        %end;\n\n        data work._etm_regex_trans(drop=start length stop REGEX len pos);\n            length _etm_occurance _etm_occurance_lc $&textCol_1_rawlength.. _etm_snipplet $&_etm_len_snip..;\n            label _etm_occurance = \"Value extracted by the RegEx Pattern: &prxPattern.\"\n                _etm_occurance_lc = \"Value extracted by the RegEx Pattern: &prxPattern.\"\n                _etm_snipplet = \"Added &snipplet_window. charachters around the found RegEx pattern to provide context\";\n        \n            if _n_ eq 1 then do;\n                REGEX=prxparse(\"&prxPattern.\");\n                if REGEX < 1 then put 'ERROR: Your specified RegEx Pattern was invalid, please check it!';\n            end;\n        \n            set &outTable.(keep=&textCol_1_name_base. _etm_ID %if &regExTargetCheck. %then %do; &regExTarget_1_name_base. %end;);\n        \n            start = 1;\n            _etm_snipplet = '';\n            length = &textCol_1_rawlength.;\n            stop = length;\n            len = stop - start + 1;\n\n            call prxnext(REGEX, start, stop, &textCol_1_name_base., pos, len);\n        \n            do while (pos gt 0);\n                _etm_occurance=ksubstr(&textCol_1_name_base., pos, len);\n                _etm_occurance_lc=lowcase(_etm_occurance);\n                _etm_snipplet=ksubstr(&textCol_1_name_base.,\n                    Max(1, pos - &snipplet_window.),\n                    Min(len + %sysevalf(2 * &snipplet_window.), &snipplet_window. + length - pos + 1)\n                );\n        \n                output;\n                call prxnext(REGEX, start, stop, &textCol_1_name_base., pos, len);\n            end;\n        \n            if _etm_occurance eq '' then output;\n        \n            retain REGEX;\n        run;\n\n        %if &createSnippetTable. %then %do;\n            data &outTableRexExContext.(drop=_etm_occurance_lc);\n                set work._etm_regex_trans(where=(strip(_etm_occurance) ne ''));\n            run;\n        %end;\n        \n        proc sql;\n            create table work._etm_occurance_cnt as\n                select  _etm_occurance_lc as _etm_occurance, count(distinct _etm_ID) as _etm_doc_cnt label = 'Number of documents containing each term extracted by the RegEx Pattern'\n                    %if &regExTargetCheck. %then %do;\n                        , mean(&regExTarget_1_name_base.) as _etm_&regExTarget_1_name_base._Mean\n                    %end;\n                    from work._etm_regex_trans\n                        group by _etm_occurance_lc\n                            order by\n                                %if &regExTargetCheck. %then %do;\n                                    _etm_&regExTarget_1_name_base._Mean descending,\n                                %end;\n                                _etm_doc_cnt descending;\n        quit;\n        \n        %if &createCustomRegExGraphics %then %do;\n            proc print data=work._etm_occurance_cnt;\n                Title \"Lowcase Pattern Matches in Column &textCol_1_name_base.\";\n                Footnote \"RegEx Pattern: &prxPattern.\";\n            run;\n            title;\n            footnote;\n        %end;\n\n        proc sql noprint;\n                select _etm_occurance into : Terms separated by '�'\n                    from work._etm_occurance_cnt(where=(_etm_doc_cnt ge &MinDocCnt.\n                        and strip(_etm_occurance) ne ''\n                        %if &regExTargetCheck. %then %do;\n                            and (_etm_&regExTarget_1_name_base._mean ge &MinTgMean.\n                            or _etm_&regExTarget_1_name_base._mean le &MaxTgMean. )\n                        %end;\n                    ));\n        quit;\n\n        ods noproctitle;\n\n        %if &sqlobs. gt 0 %then %do;\n            data &outTable.(rename=(_etm_prx=_etm_prx_0));\n                set &outTable.;\n        \n                %do i= 1 %to &sqlobs.;\n                    _etm_prx_&i.=(find(&textCol_1_name_base.,\"%scan(&terms., &i., '�')\", 'i') gt 1);\n                    label _etm_prx_&i.=\"RegEx Pattern Term &i.: %scan(&terms., &i., '�')\";\n                %end;\n        \n                _etm_prx=(sum(of _etm_prx_:) gt 0);\n                Label _etm_prx=\"RegEx Pattern Term All: &prxPattern.\";\n            run;\n\n            %if &createCustomRegExGraphics %then %do;\n                proc freq data=&outTable.;\n                    Tables %if &regExTargetCheck. ne %then %do; &regExTarget_1_name_base. %end; _etm_prx_:;\n                    Title \"Feature Statistics\";\n                    %if &regExTargetCheck. %then %do;\n                        Footnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt., MinTgMean=&MinTgMean., MaxTgMean=&MaxTgMean.\";\n                    %end;\n                    %else %do;\n                        Footnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt.\";\n                    %end;\n                run;\n                title;\n                footnote;\n\n                proc summary data=&outTable. print stackods Mean;\n                    Title \"Feature Mean\";\n                    Footnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt.\";\n                    var _etm_prx_:;\n                run;\n                title;\n                footnote;\n            %end;\n            \n            %if &regExTargetCheck. %then %do;\n                proc freq data=&outTable.;\n                    Tables &regExTarget_1_name_base.*_etm_prx_:;\n                    Title \"Feature Association with Target Variable &regExTarget_1_name_base.\";\n                    Footnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt., MinTgMean=&MinTgMean., MaxTgMean=&MaxTgMean.\";\n                run;\n                title;\n                footnote;\n\n                proc summary data=&outTable. print stackods Mean;\n                    Title \"Feature Mean within Target Variable: &regExTarget_1_name_base.\";\n                    Footnote \"RegEx Pattern: &prxPattern., MinDocCnt=&MinDocCnt., MinTgMean=&MinTgMean., MaxTgMean=&MaxTgMean.\";\n                    var _etm_prx_:;\n                    ways 0 1;\n                    class &regExTarget_1_name_base.;\n                run;\n                title;\n                footnote;\n            %end;\n        %end;\n\n        ods;\n\n        * Remove the datasets;\n        proc datasets library=work nolist;\n            delete _etm_regex_trans _etm_occurance_cnt;\n        run; quit;\n    %mend _etm_regex_extraction;\n\n    %_etm_regex_extraction;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete _etm_regex_extraction.macro;\n    run; quit;\n%end;\n\n* Get metadata from links;\n%if &getLinkMetadata. %then %do;\n    * Create a table of all links;\n    data work._etm_links(keep=_etm_lnks);\n        set &outTable.(where=(_etm_lnks_term ^= '') keep=_etm_lnks_term _etm_N_Links);\n        _etm_i = 1;\n        do while(_etm_i <= _etm_N_Links);\n            _etm_lnks = scan(_etm_lnks_term, _etm_i, ' ');\n            output;\n            _etm_i + 1;\n        end;\n    run;\n\n    * Only keep unique links to reduce querying;\n    proc sql outobs=&urlLimiter.;\n        create table work._etm_distinct_links as\n            select count(_etm_lnks) as c1, _etm_lnks\n                from work._etm_links\n                    where _etm_lnks not in (' ', 'http', 'https')\n                        order by c1;\n    run;\n\n    %let _etm_n_links = &sqlobs.;\n\n    %macro _etm_py_link_meta;\n        %do i = 1 %to %sysfunc(ceil(&_etm_n_links. / 25));\n            %let _etm_firstob = %eval(&i. * 25);\n            %let _etm_obsCount = %eval(&_etm_firstob. + 25);\n\n            %if &i. = 1 %then %do;\n                data work._etm_links;\n                    set work._etm_distinct_links(obs=25);\n                run;\n\n                proc python restart infile=pgm;\n                run;\n\n                data work._etm_link_meta_all;\n                    set work._etm_link_meta;\n                run;\n            %end;\n            %else %if &i. = %sysfunc(ceil(&_etm_n_links. / 25)) %then %do;\n                data work._etm_links;\n                    set work._etm_distinct_links(firstobs=&_etm_firstob. obs=&_etm_obsCount.);\n                run;\n\n                proc python restart infile=pgm;\n                run;\n\n                proc append base=work._etm_link_meta_all data=work._etm_link_meta;\n                run;\n            %end;\n            %else %do;\n                data work._etm_links;\n                    set work._etm_distinct_links(firstobs=&_etm_firstob.);\n                run;\n\n                proc python restart infile=pgm;\n                run;\n\n                proc append base=work._etm_link_meta_all data=work._etm_link_meta;\n                run;\n            %end;\n        %end;\n\n    %mend _etm_py_link_meta;\n\n    filename pgm \"_etm_link_meta.py\";\n\n    data _null_;\n        file pgm;\n        \n        put \"import pandas as pd\";\n        put \"import requests\";\n        put \"from bs4 import BeautifulSoup\";\n\n        if &allowUnverifiedRequests. then do;\n            put \"from urllib3.exceptions import InsecureRequestWarning\";\n            put \"requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\";\n        end;\n\n        put \" \";\n        put \"# Get the unique link table from SAS\";\n        put \"_etm_df = SAS.sd2df('work._etm_links')\";\n        put \" \";\n        put \"# Function to gather link information for each link\";\n        put \"def get_link_metadata(row):\";\n        put \"    try:\";\n\n        if &allowUnverifiedRequests. then do;\n            put \"        r = requests.get(row['_etm_lnks'], verify=False)\";\n        end;\n        else do;\n            put \"        r = requests.get(row['_etm_lnks'])\";\n        end;\n\n        put \"        html = BeautifulSoup(r, 'html.parser')\";\n        put \"        _etm_status_code = r.status_code\";\n        put \"        _etm_title = html.find('meta', attrs={'property': 'og:title'})\";\n        put \"        _etm_description = html.find('meta', attrs={'property': 'og:description'})\";\n        put \"        _etm_url = html.find('meta', attrs={'property': 'og:url'})\";\n        put \"        _etm_site_name = html.find('meta', attrs={'property': 'og:site_name'})\";\n        put \"    except:\";\n        put \"        _etm_status_code = 404\";\n        put \"        _etm_title = 'Not available'\";\n        put \"        _etm_description = 'Not available'\";\n        put \"        _etm_url = 'Not available'\";\n        put \"        _etm_site_name = 'Not available'\";\n        put \"    return _etm_status_code, _etm_title, _etm_description, _etm_url, _etm_site_name\";\n        put \" \";\n        put \"# Get the information for each link\";\n        put \"_etm_df_meta = _etm_df.apply(get_link_metadata, axis='columns', result_type='expand')\";\n        put \"_etm_df_all = pd.concat([_etm_df, _etm_df_meta], axis='columns')\";\n        put \"_etm_df_all.rename(columns = {0:'_etm_status_code', 1:'_etm_title', 2:'_etm_description', 3:'_etm_url', 4:'_etm_site_name'}, inplace = True)\";\n        put \" \";\n        put \"# Return the information to SAS\";\n        put \"SAS.df2sd(_etm_df_all, 'work._etm_link_meta')\";\n    run;\n    \n    %_etm_py_link_meta;\n\n    filename pgm clear;\n    \n    * Add the link metadata back to table;\n    %macro _etm_add_link_meta;\n        proc sql noprint;\n            select max(_etm_N_Links) into :_etm_max_links\n                from &outTable.;\n        run;\n        \n        proc sql;\n            create table work._etm_link_combined as\n                select a.*,\n                    %do i = 1 %to &_etm_max_links.;\n                        %if &i. > 1 %then %do;\n                            ,\n                        %end;\n                        t&i.._etm_status_code as _etm_status_code_&i. label=\"HTTP Status Code of the &i.. Link\",\n                        t&i.._etm_title as _etm_title_&i. label=\"Website Title of the &i.. Link\",\n                        t&i.._etm_description as _etm_description_&i. label=\"Website Description of the &i.. Link\",\n                        t&i.._etm_url as _etm_url_&i. label=\"Website URL of the &i.. Link\",\n                        t&i.._etm_site_name as _etm_site_name_&i. label=\"Website Name of the &i.. Link\"\n                    %end;\n                        from &outTable. as a\n                            %do i = 1 %to &_etm_max_links.;\n                                left join work._etm_link_meta as t&i.\n                                    on a._etm_lnks_&i. = t&i.._etm_lnks\n                            %end;\n        ;run;\n    \n        data &outTable.;\n            set work._etm_link_combined;\n        run;\n    %mend _etm_add_link_meta;\n    \n    %_etm_add_link_meta;\n\n    * Remove datasets;\n    proc datasets library=work nolist;\n        delete _etm_links _etm_distinct_links _etm_link_meta _etm_link_meta_all _etm_link_combined;\n    run;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n       delete _etm_py_link_meta.macro _etm_add_link_meta.macro;\n    run;\n%end;\n\n* Add a language to the dataset;\n%if &useTextAnalytics. %then %do;\n    * Sort the data by ID for results merge at the end;\n    proc sort data=&outTable.;\n        by _etm_ID;\n    run;\n\n    cas _etm_sess sessopts=(caslib=casuser);\n    libname _etm_cas cas caslib='casuser' datalimit=all;\n\n    %macro _etm_add_language;\n        * Automatic language detection;\n        %if &howLanguage. %then %do;\n            * Load the data into CAS;\n            proc casutil session=_etm_sess;\n                load data=&outTable. outcaslib='casuser'\n                casout='_etm_lang_detect' replace;\n            run;\n            \n            * Detect the language of each text;\n            proc cas;\n               session _etm_sess;\n            \n                output log;\n            \n                textManagement.identifyLanguage /\n                    casOut={name='_etm_lang_detected', replace=True}\n                    docId='_etm_ID'\n                    table={name='_etm_lang_detect'}\n                    text=\"&textCol_1_name_base.\";\n            run; quit;\n            \n            * Pull the data down from CAS into SPRE;\n            data work._etm_lang(rename=(_language_=_etm_lang));\n                set _etm_cas._etm_lang_detected(where=(_language_^=' '));\n                label _language_ = 'Language of the text';\n            run;\n        \n            proc sort data=work._etm_lang;\n                by _etm_ID;\n            run;\n            \n            * Add the data to the output dataset;\n            data &outTable.;\n                merge &outTable. work._etm_lang;\n                by _etm_ID;\n            run;\n\n            * Create a bar chart of the detected languages;\n            %if &createLanguagePlot. %then %do;\n                ods graphics / reset imagemap;\n                title3 \"Distribution of the Detected Languages\";\n                proc sgplot data = &outTable.;\n                    vbar _etm_lang;\n                run;\n                title3;\n            %end;\n\n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_lang;\n            run;\n        %end;\n        %else %do;\n            * Language specified by the user;\n            data &outTable.;\n                set &outTable.;\n\n                length _etm_lang $2.;\n                label _etm_lang = 'Language of the text';\n\n                _etm_lang = \"&userSpecifiedLanguage.\";\n\n                * Handle the case of empty text;\n                if &textCol_1_name_base. = '' then do;\n                    _etm_lang = ' ';\n                end;\n            run;\n        %end;\n    %mend _etm_add_language;\n\n    %_etm_add_language;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete _etm_add_language.macro;\n    run; quit;\n%end;\n\n* Create translation of shorthand language to long formn language;\n* This dataset is used by actions that run for each language;\n%if &profileText. or &createTopics. or &createPredefinedConcepts. or &useCustomConcepts. or &createBoolRules. %then %do;\n    * Long name of language for proc textmine;\n    data work._etm_lang_trans;\n        infile datalines delimiter=',';\n        length _etm_long_lang $15 _etm_short_lang $2;\n        input _etm_long_lang $ _etm_short_lang $;\n             \n        datalines;\nArabic, AR\nChinese, ZH\nCroatian, HR\nCzech, CS\nDanish, DA\nDutch, NL\nEnglish, EN\nFinnish, FI\nFrench, FR\nGerman, DE\nGreek, EL\nHebrew, IW\nHindi, HI\nHungarian, HU\nIndonesian, IN\nItalian, IT\nJapanese, JA\nKazakh, KK\nKorean, KO\nNorwegian, NO\nPersian, FA\nPolish, PL\nPortuguese, PT\nRomanian, RO\nRussian, RU\nSlovak, SK\nSlovene, SL\nSpanish, ES\nSwedish, SV\nTagalog, TL\nThai, TH\nTurkish, TR\nVietnamese, VI\n;\n    run;\n%end;\n\n* Profile the text corpus;\n%if &profileText. %then %do;\n    proc casutil session=_etm_sess;\n        load data=&outTable. outcaslib='casuser'\n        casout='_etm_profile_text' replace;\n    run;\n    \n    %macro _etm_profile_text;\n        * Select all distinct languages in the dataset;\n        proc sql noprint;\n            select distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n                from &outTable.\n                    where _etm_lang ne ' ';\n        run;\n\n        %do i=1 %to &_etm_lang_cnt.;\n            * Create a separate dataset for each language;\n            data _etm_cas._etm_lang_&&_etm_lang&i.;\n                set &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n            run;\n\n            data _null_;\n                set work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n                call symputx('_etm_long_lang', _etm_long_lang);\n            run;\n\n            *Run the text profiling;\n            proc cas;\n                session _etm_sess;\n                        \n                output log;\n            \n                textManagement.profileText /\n                casOut = {name = '_etm_profile_text_out', replace = True}\n    \n                %if &compareReferenceCorpus. %then %do;\n                    referenceData = True\n                %end;\n    \n                documentId = '_etm_ID'\n                documentOut = {name = '_etm_document_out', replace = True}\n                language = \"&_etm_long_lang.\"\n                table = {name = '_etm_profile_text'}\n                text = \"&textCol_1_name_base.\";\n            run; quit;\n    \n            ods noproctitle;\n\n            * Print the Results of the Profiling action to the Results;\n            title3 \"Profile Text for the &_etm_long_lang. texts in the Corpus\";\n            proc cas;\n                session _etm_sess;\n    \n                table.fetch / table= {name = '_etm_profile_text_out'};\n            run; quit;\n            title3;\n\n            * Print Word and Sentence Count Graphs;\n            %if &createProfileTextGraphs. %then %do;\n                title \"Sentences Count in Documents for &_etm_long_lang.\";\n                proc sgplot data=_etm_cas._etm_document_out;\n                    vbar _num_sentences_;\n                    yaxis label='Number of Documents' grid;\n                    xaxis label='Number of Sentences';\n                run;\n                title;\n\n                title \"Word Count in Documents for &_etm_long_lang.\";\n                proc sgplot data=&outTable.;\n                    vbar _etm_wrd_cnt;\n                    yaxis label='Number of Documents' grid;\n                    xaxis label='Number of Words';\n                run;\n                title;\n            %end;\n\n        %end;\n\n        * Add new features derived from the Profiling action;\n        %if &createNumSentences. or &createMaxTokenSentence. %then %do;\n            proc sql;\n                create table work._etm_profile_text as\n                    select _etm_ID\n                        %if &createNumSentences. %then %do;\n                            , _num_sentences_ as _etm_num_sentences label = 'Number of sentences in the Text'\n                        %end;\n                        %if &createMaxTokenSentence. %then %do;\n                            , _max_tokens_sentence_ as _etm_max_tokens_sentence label = 'Number of Tokens in the longest Sentence in the Text'\n                        %end;\n                        from _etm_cas._etm_document_out\n                            order by _etm_ID;\n            run;\n\n            data &outTable.;\n                merge &outTable. work._etm_profile_text;\n                by _etm_ID;\n            run;\n\n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_profile_text;\n            run; quit;\n        %end;\n\n    %mend _etm_profile_text;\n    \n    %_etm_profile_text;\n\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete _etm_profile_text.macro;\n    run; quit;\n%end;\n\n* Detect the sentiment of each text;\n%if &detectSentiment. %then %do;\n    %macro _etm_by_lang;\n        * Select all distinct languages in the dataset;\n        proc sql noprint;\n            select distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n                from &outTable.\n                    where _etm_lang ne ' ';\n        run;\n    \n        %do i=1 %to &_etm_lang_cnt.;\n            * If text profiling is not selected, then the language split has to be created;\n            %if not &profileText. %then %do;\n                * Create a separate dataset for each language;\n                data _etm_cas._etm_lang_&&_etm_lang&i.;\n                    set &outTable.(where=(_etm_lang=\"&&&&_etm_lang&i.\"));\n                run;\n            %end;\n\n            data _null_;\n                set work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n                call symputx('_etm_long_lang', _etm_long_lang);\n            run;\n    \n            * Score the sentiment for each text;\n            proc cas;\n                 session _etm_sess;\n            \n                output log;\n            \n                sentimentAnalysis.applySent /\n                        docId='_etm_ID'\n                        text=\"&textCol_1_name_base.\"\n                        language=\"&_etm_long_lang.\"\n                        table={name=\"_etm_lang_&&_etm_lang&i.\"}\n                        casOut={name=\"_etm_sent_&&_etm_lang&i.\", replace=True};\n                run; \n            quit;\n\n            * Move the sentiment data from CAS to SPRE;\n            data work._etm_sent_&&_etm_lang&i.;\n                length _etm_sentiment $32. _etm_sentiment_score 8.;\n                label _etm_sentiment = 'Sentiment of the text'\n                    _etm_sentiment_score = 'Score value for the sentiment of the text';\n\n                set _etm_cas._etm_sent_&&_etm_lang&i.;\n\n                _etm_sentiment = _sentiment_;\n                _etm_sentiment_score = _score_;\n\n                drop _sentiment_ _score_;\n            run;\n\n            proc sort data=work._etm_sent_&&_etm_lang&i.;\n                by _etm_ID;\n            run;\n\n            * Add the sentiment and score to the data;\n            data &outTable.;\n                merge &outTable. work._etm_sent_&&_etm_lang&i.;\n                by _etm_ID;\n            run;\n    \n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_sent_&&_etm_lang&i.;\n            run; quit;\n        %end;\n\n        * Create a bar chart of the sentiment languages;\n        %if &createSentimentPlot. %then %do;\n            ods graphics / reset imagemap;\n            title3 \"Distribution of the Sentiment by Languages\";\n            proc sgplot data = &outTable.;\n                vbar _etm_sentiment / group = _etm_lang groupdisplay=stack;\n            run;\n            title3;\n        %end;\n    %mend _etm_by_lang;\n    \n    %_etm_by_lang;\n    \n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n       delete _etm_by_lang.macro;\n    run; quit;\n%end;\n\n* Apply the SAS Predefined Concepts to the data;\n%if &createPredefinedConcepts. and &conceptList_count. > 0 %then %do;\n    %macro _etm_predefined_concepts;\n        * Bring the user selected concepts in the format for a where clause;\n        data _null_;\n            _etm_prcncpt_all = \"'\" || \"&conceptList_1.\" || \"'\"\n            %do j = 1 %to &conceptList_count.;\n                || \",'\" || \"&&conceptList_&j.\" || \"'\"\n            %end;\n            ;\n            call symputx('_etm_prcncpt_all', _etm_prcncpt_all);\n        run;\n\n        * Select all distinct languages in the dataset;\n        proc sql noprint;\n            select distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n                from &outTable.\n                    where _etm_lang ne ' ';\n        run;\n\n        %do i=1 %to &_etm_lang_cnt.;\n            * If text profiling and sentiment detection are not selected, then the language split has to be created;\n            %if not &profileText. and not &detectSentiment. %then %do;\n                * Create a separate dataset for each language;\n                data _etm_cas._etm_lang_&&_etm_lang&i.;\n                    set &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n                run;\n            %end;\n\n            data _null_;\n                set work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n                call symputx('_etm_long_lang', _etm_long_lang);\n            run;\n\n            * Apply the SAS predefined concepts to the text;\n            proc cas;\n                session _etm_sess;\n            \n                output log;\n            \n                textRuleDevelop.compileConcept /\n                        casOut = {name = '_etm_comp_Concepts', replace = True}\n                        enablePredefined = True\n                        language = \"&_etm_long_lang.\";\n                run;\n            \n                textRuleScore.applyConcept /\n                        casOut = {name = \"_etm_concepts_&&_etm_lang&i.\", replace = True}\n                        language = \"&_etm_long_lang.\"\n                        docId = '_etm_ID'\n                        model = {name = '_etm_comp_Concepts'}\n                        table = {name = \"_etm_lang_&&_etm_lang&i.\"}\n                        text = \"&textCol_1_name_base.\";\n               run;\n            quit;\n        %end;\n\n        * Append all concepts in one table;\n        data work._etm_all_concepts(drop=_start_ _end_ _canonical_form_ _path_);\n            length _etm_match_text $&textCol_1_rawlength. _etm_concept $15.;\n            label _etm_match_text = 'The matched text for the concept'\n                _etm_concept = 'The concept that was found in the text';\n            set\n        %do i=1 %to &_etm_lang_cnt.;\n            _etm_cas._etm_concepts_&&_etm_lang&i.(where=(_concept_ in (&_etm_prcncpt_all.)))\n        %end;\n            ;\n            _etm_match_text = _match_text_;\n            _etm_concept = _concept_;\n            drop _match_text_ _concept_;\n        run;\n\n        * Sort the data by the document ID to do by group processing;\n        proc sort data=work._etm_all_concepts;\n            by _etm_ID _etm_concept;\n        run;\n\n        * Generate the new features based on the predefined concepts;\n        data work._etm_all_concepts;\n            set work._etm_all_concepts;\n            by _etm_ID _etm_concept;\n        \n            * New Features from Concepts;\n            length _etm_total_concepts 8.;\n            label _etm_total_concepts = 'Total Number of Concepts found in the Text';\n\n            * Columns per Selected Predefined Concept;\n            %do k=1 %to &conceptList_count.;\n                length _etm_&&conceptList_&k.._count 8.;\n                label _etm_&&conceptList_&k.._count = \"Count for &&conceptList_&k. in the Text\";\n            %end;\n\n            %if &createConcatedPreConcepts. %then %do;\n                %do l=1 %to &conceptList_count.;\n                    length _etm_&&conceptList_&l.._cat $&textCol_1_rawlength.;\n                    label _etm_&&conceptList_&l.._cat = \"Concatenated List of all Matched Texts for the Concept _etm_&&conceptList_&l.._cat\";\n                %end;\n            %end;\n\n            if first._etm_concept then do;\n                %do m=1 %to &conceptList_count.;\n                    _etm_&&conceptList_&m.._count = 1;\n\n                    %if &createConcatedPreConcepts. %then %do;\n                        _etm_&&conceptList_&m.._cat = '';\n                        if _etm_concept = \"&&conceptList_&m.\" then do;\n                            _etm_&&conceptList_&m.._cat = _etm_match_text;\n                        end;\n                    %end;\n                %end;\n            end;\n            else do;\n                %do n=1 %to &conceptList_count.;\n                    if _etm_concept = \"&&conceptList_&n.\" then do;\n                        _etm_&&conceptList_&n.._count + 1;\n\n                        %if &createConcatedPreConcepts. %then %do;\n                            _etm_&&conceptList_&n.._cat = strip(_etm_&&conceptList_&n.._cat) || '||' || _etm_match_text;\n                        %end;\n                    end;\n                %end;\n            end;\n\n            if first._etm_ID and last._etm_ID then do;\n                _etm_total_concepts = 1;\n                output;\n            end;\n            else if first._etm_ID then do;\n                _etm_total_concepts = 1;\n            end;\n            else if last._etm_ID then do;\n                _etm_total_concepts + 1;\n                output;\n            end;\n            else do;\n                _etm_total_concepts + 1;\n            end;\n\n            retain _etm_total_concepts\n            %do o=1 %to &conceptList_count.;\n                _etm_&&conceptList_&o.._count\n                %if &createConcatedPreConcepts. %then %do;\n                    _etm_&&conceptList_&o.._cat\n                %end;\n            %end;\n            ;\n        run;\n\n        data &outTable.;\n            merge &outTable. work._etm_all_concepts;\n            by _etm_ID;\n        run;\n\n        * Create a bar chart of the extracted SAS Predefined Concepts;\n        %if &createPreConceptPlot. %then %do;\n            ods graphics / reset imagemap;\n            title3 \"Distribution of the Extracted SAS Predefined Concepts by Languages\";\n            proc sgplot data = &outTable.;\n                vbar _etm_concept / group=_etm_lang;\n            run;\n            title3;\n        %end;\n\n        * Remove datasets;\n        proc datasets library=work nolist;\n            delete _etm_all_concepts;\n        run; quit;\n    %mend _etm_predefined_concepts;\n\n    %_etm_predefined_concepts;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete _etm_predefined_concepts.macro;\n    run; quit;\n%end;\n\n%if &singlePreConcepts. %then %do;\n    %macro _etm_create_single_precon;\n        * Get the max number of concepts per Text;\n        proc sql noprint;\n                %do i=1 %to &conceptList_count.;\n                    select max(_etm_&&conceptList_&i.._count) into :_etm_max_&&conceptList_&i.\n                        from &outTable.;\n                %end;\n        run;\n\n        %do j=1 %to &conceptList_count.;\n            data &outTable.;\n                set &outTable.;\n                %do k=1 %to &conceptList_count.;\n                    %do m=1 %to &&&&_etm_max_&&conceptList_&k.;\n                        length _etm_&&conceptList_&k.._&m. $&textCol_1_rawlength.;\n                        label _etm_&&conceptList_&k.._&m. = \"&m.. &&conceptList_&k. Concept in the Text\";\n                        _etm_&&conceptList_&k.._&m. = scan(_etm_&&conceptList_&k.._cat, &m., '||');\n                    %end;\n                %end;\n            run;\n        %end;\n\n    %mend _etm_create_single_precon;\n\n    %_etm_create_single_precon;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n       delete _etm_create_single_precon.macro;\n    run;\n%end;\n\n* Extract Custom Concepts from the Text;\n%if &useCustomConcepts. %then %do;\n    %macro addCustomConcepts;\n        * Load the data into CAS;\n        %if not &compiledCustomConcepts %then %do;\n            proc casutil session=_etm_sess;\n                load data=&custConInTable. outcaslib='casuser'\n                casout='_etm_custom_concept' replace;\n            run;\n        %end;\n        %else %do;\n            proc casutil session=_etm_sess;\n                load casdata=\"&custConInTable_Name.\" incaslib=\"&custConInTable_Lib.\"\n                casout='_etm_custom_concept' outcaslib='casuser' replace;\n            run;\n        %end;\n\n        * Select all distinct languages in the dataset;\n        proc sql noprint;\n            select distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n                from &outTable.\n                    where _etm_lang ne ' ';\n        run;\n\n        %do i=1 %to &_etm_lang_cnt.;\n            * If the language split has to be created;\n            %if not &profileText. and not &detectSentiment. and not &createPredefinedConcepts. %then %do;\n                * Create a separate dataset for each language;\n                data _etm_cas._etm_lang_&&_etm_lang&i.;\n                    set &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n                run;\n            %end;\n\n            data _null_;\n                set work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n                call symputx('_etm_long_lang', _etm_long_lang);\n            run;\n\n            proc cas;\n\n                session _etm_sess;\n\n                output log;\n                \n                %if not &compiledCustomConcepts. and &i. eq 1 %then %do;\n                    textRuleDevelop.compileConcept /\n                            casOut={name='_etm_custom_concept', replace=True} \n                            config=\"&customConInTable_1_name_base.\"\n                            table={name='_etm_custom_concept'};\n                        run;\n                %end;\n\n                textRuleScore.applyConcept /\n                        casOut = {name = \"_etm_cus_concepts_&&_etm_lang&i.\", replace = True}\n                        language = \"&_etm_long_lang.\"\n                        docId = '_etm_ID'\n                        model = {name = '_etm_custom_concept'}\n                        table = {name = \"_etm_lang_&&_etm_lang&i.\"}\n                        text = \"&textCol_1_name_base.\";\n                    run;\n            quit;\n        %end;\n\n        * Append all concepts in one table;\n        data work._etm_all_custom_concepts(drop=_start_ _end_ _canonical_form_ _path_);\n            length _etm_custom_match_text $&textCol_1_rawlength. _etm_custom_concept $256.;\n            label _etm_custom_match_text = 'The matched text for the concept'\n                _etm_custom_concept = 'The concept that was found in the text';\n            set\n        %do i=1 %to &_etm_lang_cnt.;\n            _etm_cas._etm_cus_concepts_&&_etm_lang&i.\n        %end;\n            ;\n            _etm_custom_match_text = _match_text_;\n            _etm_custom_concept = _concept_;\n            drop _match_text_ _concept_;\n        run;\n\n        * Sort the data by the document ID to do by group processing;\n        proc sort data=work._etm_all_custom_concepts;\n            by _etm_ID _etm_custom_concept;\n        run;\n\n        * Count the number of distinct custom concepts found in the data;\n        proc sql noprint;\n            select distinct _etm_custom_concept into :_etm_custom_concept_1-\n                from work._etm_all_custom_concepts;\n\n            select count(distinct _etm_custom_concept) into :_etm_custom_concept_cnt\n                from work._etm_all_custom_concepts;\n        run;\n\n        * Generate the new features based on the predefined concepts;\n        data work._etm_all_custom_concepts;\n            set work._etm_all_custom_concepts;\n            by _etm_ID _etm_custom_concept;\n        \n            * New Features from Concepts;\n            length _etm_total_custom_concepts 8.;\n            label _etm_total_custom_concepts = 'Total Number of Custom Concepts found in the Text';\n\n            * Columns per Selected Predefined Concept;\n            %do k=1 %to &_etm_custom_concept_cnt.;\n                length _etm_&&_etm_custom_concept_&k.._count 8.;\n                label _etm_&&_etm_custom_concept_&k.._count = \"Count for &&_etm_custom_concept_&k. in the Text\";\n            %end;\n\n            %if &createConcatedCustomConcepts. %then %do;\n                %do l=1 %to &_etm_custom_concept_cnt.;\n                    length _etm_&&_etm_custom_concept_&l.._cat $&textCol_1_rawlength.;\n                    label _etm_&&_etm_custom_concept_&l.._cat = \"Concatenated List of all Matched Texts for the Concept _etm_&&_etm_custom_concept_&l.._cat\";\n                %end;\n            %end;\n\n            if first._etm_custom_concept then do;\n                %do m=1 %to &_etm_custom_concept_cnt.;\n                    _etm_&&_etm_custom_concept_&m.._count = 1;\n\n                    %if &createConcatedCustomConcepts. %then %do;\n                        _etm_&&_etm_custom_concept_&m.._cat = '';\n                        if _etm_custom_concept = \"&&_etm_custom_concept_&m.\" then do;\n                            _etm_&&_etm_custom_concept_&m.._cat = _etm_custom_match_text;\n                        end;\n                    %end;\n                %end;\n            end;\n            else do;\n                %do n=1 %to &_etm_custom_concept_cnt.;\n                    if _etm_custom_concept = \"&&_etm_custom_concept_&n.\" then do;\n                        _etm_&&_etm_custom_concept_&n.._count + 1;\n\n                        %if &createConcatedCustomConcepts. %then %do;\n                            _etm_&&_etm_custom_concept_&n.._cat = strip(_etm_&&_etm_custom_concept_&n.._cat) || '||' || _etm_custom_match_text;\n                        %end;\n                    end;\n                %end;\n            end;\n\n            if first._etm_ID and last._etm_ID then do;\n                _etm_total_custom_concepts = 1;\n                output;\n            end;\n            else if first._etm_ID then do;\n                _etm_total_custom_concepts = 1;\n            end;\n            else if last._etm_ID then do;\n                _etm_total_custom_concepts + 1;\n                output;\n            end;\n            else do;\n                _etm_total_custom_concepts + 1;\n            end;\n\n            retain _etm_total_custom_concepts\n\n            %do o=1 %to &_etm_custom_concept_cnt.;\n                _etm_&&_etm_custom_concept_&o.._count\n                %if &createConcatedCustomConcepts. %then %do;\n                    _etm_&&_etm_custom_concept_&o.._cat\n                %end;\n            %end;\n            ;\n        run;\n\n        data &outTable.;\n            merge &outTable. work._etm_all_custom_concepts;\n            by _etm_ID;\n        run;\n\n        data &outTable.;\n            merge &outTable. work._etm_all_custom_concepts;\n            by _etm_ID;\n        run;\n\n        * Create a bar chart of the extracted Custom Concepts;\n        %if &createCustomConceptPlot. %then %do;\n            ods graphics / reset imagemap;\n            title3 \"Distribution of the Extracted Custom Concepts by Languages\";\n            proc sgplot data = &outTable.;\n                vbar _etm_custom_concept / group=_etm_lang;\n            run;\n            title3;\n        %end;\n    %mend addCustomConcepts;\n\n    %addCustomConcepts;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete addCustomConcepts.macro;\n    run; quit;\n%end;\n\n* Create separated columns for the Custom Concepts;\n%if &singleCustomConcepts. %then %do;\n    %macro _etm_create_single_custom_con;\n        * Count the number of distinct custom concepts found in the data;\n        proc sql noprint;\n            select distinct _etm_custom_concept into :_etm_custom_concept_1-\n                from work._etm_all_custom_concepts;\n\n            select count(distinct _etm_custom_concept) into :_etm_custom_concept_cnt\n                from work._etm_all_custom_concepts;\n        run;\n\n        * Get the max number of concepts per Text;\n        proc sql noprint;\n                %do i=1 %to &_etm_custom_concept_cnt.;\n                    select max(_etm_&&_etm_custom_concept_&i.._count) into :_etm_max_&&_etm_custom_concept_&i.\n                        from &outTable.;\n                %end;\n        run;\n\n        %do j=1 %to &_etm_custom_concept_cnt.;\n            data &outTable.;\n                set &outTable.;\n                %do k=1 %to &_etm_custom_concept_cnt.;\n                    %do m=1 %to &&&&_etm_max_&&_etm_custom_concept_&k.;\n                        length _etm_&&_etm_custom_concept_&k.._&m. $&textCol_1_rawlength.;\n                        label _etm_&&_etm_custom_concept_&k.._&m. = \"&m.. &&_etm_custom_concept_&k. Concept in the Text\";\n                        _etm_&&_etm_custom_concept_&k.._&m. = scan(_etm_&&_etm_custom_concept_&k.._cat, &m., '||');\n                    %end;\n                %end;\n            run;\n        %end;\n    %mend _etm_create_single_custom_con;\n\n    %_etm_create_single_custom_con;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n       delete _etm_create_single_custom_con.macro;\n    run;\n%end;\n\n* Create Text Topics for each Language;\n%if &createTopics. %then %do;\n    %macro _etm_topic_discovery;\n\n        * Select all distinct languages in the dataset;\n        * Filter languages that have more then 50 rows;\n        proc sql noprint;\n            create table work._etm_lang_grp as\n            select count(_etm_lang) as _etm_lang_cnt, _etm_lang\n                from &outTable.\n                    group by _etm_lang\n                        having _etm_lang ne ' ';\n        run;\n\n        proc sql noprint;\n            select distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n                from work._etm_lang_grp\n                    where _etm_lang ne ' ' and _etm_lang_cnt >= 50;\n        run;\n        \n        ods noproctitle;\n    \n        %do i=1 %to &_etm_lang_cnt.;\n    \n            * If the language split has to be created;\n            %if not &profileText. and not &detectSentiment. and not &createPredefinedConcepts. and not &useCustomConcepts. %then %do;\n                * Create a separate dataset for each language;\n                data _etm_cas._etm_lang_&&_etm_lang&i.;\n                    set &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n                run;\n            %end;\n    \n            * Load default stop lists;\n            proc casutil;\n                load casdata=\"&&_etm_lang&i.._stoplist.sashdat\" incaslib='referencedata'\n                    casout=\"_etm_&&_etm_lang&i.._stoplist\" outcaslib='casuser' replace;\n            quit;\n\n            data _null_;\n                set work._etm_lang_trans(where=(lowcase(_etm_short_lang) eq \"&&_etm_lang&i.\"));\n                call symputx('_etm_long_lang', _etm_long_lang);\n            run;\n    \n            %if &useBestPractise. %then %do;\n                * Create the text topics;\n                proc cas;\n                    session _etm_sess;\n\n                    output log;\n\n                    textMining.tmMine /\n                        language = \"&_etm_long_lang.\"\n                        documents = \"_etm_lang_&&_etm_lang&i.\"\n                        text = \"&textCol_1_name_base.\"\n                        docid = \"_etm_ID\"\n\n                        stopList = {name = \"_etm_&&_etm_lang&i.._stoplist\"}\n                        nounGroups = False\n                        tagging = False\n                        entities = 'NONE'\n                        reduce = 4\n                        resolution = 'MED'\n                        rotate = 'VARIMAX'\n                        maxK = 100\n                        numLabels = 20\n\n                        %if &createScreePlotSVD. %then %do;\n                            s = {name = \"_etm_&&_etm_lang&i.._svds\", replace = True}\n                        %end;\n\n                        %if &useTopicCreationTbD. %then %do;\n                            parent = {name = \"_etm_parent_&&_etm_lang&i.\", replace = True}\n                            terms = {name = \"_etm_terms_&&_etm_lang&i.\", replace = True}\n                        %end;\n\n                        docPro = {name = \"_etm_&&_etm_lang&i.._doc_pro\", replace = True}\n                        topics = {name = \"_etm_&&_etm_lang&i.._topics\", replace = True};\n                run;\n            %end;\n            %else %do;\n                %if &selectEntities. %then %do;\n                    %if &createPredefinedConcepts. %then %do;\n                        data _null_;\n                            _etm_prcncpt_all = \"'\" || \"&conceptList_1.\" || \"'\"\n                            %do j = 1 %to &conceptList_count.;\n                                || \",'\" || \"&&conceptList_&j.\" || \"'\"\n                            %end;\n                            ;\n                            call symputx('_etm_prcncpt_all', _etm_prcncpt_all);\n                        run;\n                    %end;\n                    %if &useCustomConcepts. %then %do;\n                        proc sql noprint;\n                            select distinct _etm_custom_concept into :_etm_custom_concept_1-\n                                from work._etm_all_custom_concepts;\n                \n                            select count(distinct _etm_custom_concept) into :_etm_custom_concept_cnt\n                                from work._etm_all_custom_concepts;\n                        run;\n                \n                        data _null_;\n                            _etm_custcncpt_all = \"'\" || \"&_etm_custom_concept_1.\" || \"'\"\n                            %do j = 1 %to &_etm_custom_concept_cnt.;\n                                || \",'\" || \"&&_etm_custom_concept_&j.\" || \"'\"\n                            %end;\n                            ;\n                            call symputx('_etm_custcncpt_all', _etm_custcncpt_all);\n                        run;\n                    %end;\n                %end;\n            \n                proc cas;\n\n                    session _etm_sess;\n\n                    output log;\n            \n                    textMining.tmMine /\n                            language = \"&_etm_long_lang.\"\n                            documents = {name = \"_etm_lang_&&_etm_lang&i.\"}\n                            docId = \"_etm_ID\"\n            \n                            entities = %if &extractEntities. %then %do; 'std' %end;\n                            %else %do; 'none' %end;\n            \n                            noungroups = %if &posTagging. %then %do; True %end;\n                            %else %do; False %end;\n            \n                            stemming = %if &stemTerms. %then %do; True %end;\n                            %else %do; False %end;\n                            \n                            tagging = %if &extractNounGroups. %then %do; True %end;\n                            %else %do; False %end;\n            \n                            reduce = &minOccKeep.\n            \n                            cellWeight = %if &cellWeight. %then %do; 'log' %end;\n                            %else %do; 'none' %end;\n            \n                            termWeight = \"&termWeight.\"\n            \n                            %if &useStopWords. %then %do;\n                                stopList = {name = \"_etm_&&_etm_lang&i.._stoplist\"}\n                            %end;\n            \n                            norm = \"&normProjects.\"\n                            \n                            %if &numTopics. %then %do;\n                                k = &numTopicsK.\n                            %end;\n                            %else %do;\n                                maxK = &numTopicsMaxK.\n                            %end;\n            \n                            resolution = \"&resolutionLevel.\"\n            \n                            rotate = \"&rotationType.\"\n            \n                            numLabels = &numLabels.\n            \n                            %if &selectEntities. %then %do;\n                                selectEntity={tagList={\n                                    %if &createPredefinedConcepts. and &useCustomConcepts. %then %do;\n                                        &_etm_prcncpt_all., &_etm_custcncpt_all.\n                                    %end;\n                                    %else %if &createPredefinedConcepts. %then %do;\n                                        &_etm_prcncpt_all.\n                                    %end;\n                                    %else %do;\n                                        &_etm_custcncpt_all.\n                                    %end;\n                                }}\n            \n                                %if &useCustomConcepts. %then %do;\n                                    defaultEntitiesPriority = &defaultEntityPrio.\n\n                                    liti={name='_etm_custom_concept',\n                                    computedVars={name='_priority_'}\n                                    %if not &hasCustomPrio. %then %do;\n                                        , computedVarsProgram=\"_priority_ = %sysevalf(&defaultEntityPrio. + 1);\"\n                                    %end;\n                                    }\n                                %end;\n                            %end;\n\n                            text = \"&textCol_1_name_base.\"\n\n                            %if &createScreePlotSVD. %then %do;\n                                s = {name = \"_etm_&&_etm_lang&i.._svds\", replace = True}\n                            %end;\n\n                            %if &useTopicCreationTbD. %then %do;\n                                parent = {name = \"_etm_parent_&&_etm_lang&i.\", replace = True}\n                                terms = {name = \"_etm_terms_&&_etm_lang&i.\", replace = True}\n                            %end;\n\n                            docPro = {name = \"_etm_&&_etm_lang&i.._doc_pro\", replace = True}\n                            topics = {name = \"_etm_&&_etm_lang&i.._topics\", replace = True};\n                        run;\n                quit;\n            %end;\n    \n            %if &createScreePlotSVD. %then %do;\n                ods graphics / reset imagemap;\n                title3 \"Scree Plot of SVD for &&_etm_lang&i.\";\n                proc sgplot data = _etm_cas._etm_&&_etm_lang&i.._svds;\n                    vline _id_ / \n                        response = _s_\n                        nostatlabel \n                        stat = Mean \n                        markers;\n                    xaxis label='Topic';\n                    yaxis grid label='Singular Value';\n                run;\n                title3;\n            %end;\n    \n            proc sort data=_etm_cas._etm_&&_etm_lang&i.._doc_pro out=work._etm_&&_etm_lang&i.._doc_pro;\n                by _etm_ID;\n            run;\n\n            %let _etm_dsid=%sysfunc(open(work._etm_&&_etm_lang&i.._doc_pro));\n            %let _etm_n=%sysfunc(attrn(&_etm_dsid., nvars));\n\n            * Rename the topic columns to start with _etm_;\n            data work._etm_&&_etm_lang&i.._doc_pro(rename=(_etm__etm_id=_etm_id));\n                set work._etm_&&_etm_lang&i.._doc_pro(rename=(\n\n                %do j = 2 %to &_etm_n.;\n                    %let _etm_var=%sysfunc(varname(&_etm_dsid., &j.));\n                    &_etm_var. = _etm_&&_etm_lang&i.._&_etm_var.\n                %end;));\n\n                %let _etm_rc=%sysfunc(close(&_etm_dsid.));\n            run;\n\n            data &outTable.;\n                merge &outTable. work._etm_&&_etm_lang&i.._doc_pro;\n                by _etm_ID;\n            run;\n\n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_lang_grp _etm_&&_etm_lang&i.._doc_pro;\n            run; quit;\n\n            ods proctitle;\n        %end;\n    %mend _etm_topic_discovery;\n\n    %_etm_topic_discovery;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete _etm_topic_discovery.macro;\n    run; quit;\n%end;\n\n* Create BoolRules for a target variable associated wiht the text;\n%if &createBoolRules. %then %do;\n    %macro _etm_create_boolRule;\n\n        ods noproctitle;\n\n        * Select all distinct languages in the dataset;\n        * Filter languages that have more then 50 rows;\n        proc sql noprint;\n            create table work._etm_lang_grp as\n            select count(_etm_lang) as _etm_lang_cnt, _etm_lang\n                from &outTable.\n                    group by _etm_lang\n                        having _etm_lang ne ' ';\n        run;\n\n        proc sql noprint;\n            select distinct _etm_lang, count(distinct _etm_lang) into :_etm_lang1-, :_etm_lang_cnt\n                from work._etm_lang_grp\n                    where _etm_lang ne ' ' and _etm_lang_cnt >= 50;\n        run;\n        \n        %do i=1 %to &_etm_lang_cnt.;\n            * If the language split has to be created;\n            %if not &profileText. and not &detectSentiment. and not &createPredefinedConcepts. and not &useCustomConcepts. and not &createTopics. %then %do;\n                * Create a separate dataset for each language;\n                data _etm_cas._etm_lang_&&_etm_lang&i.;\n                    set &outTable.(where=(_etm_lang=\"&&_etm_lang&i.\"));\n                run;\n            %end;\n\n            * Load the stop word list if it not loaded already;\n            %if not &createTopics. %then %do;\n                * Load default stop lists;\n                proc casutil;\n                    load casdata=\"&&_etm_lang&i.._stoplist.sashdat\" incaslib='referencedata'\n                        casout=\"_etm_&&_etm_lang&i.._stoplist\" outcaslib='casuser' replace;\n                quit;\n            %end;\n\n            options label;\n\n            * If the user does jas a termByDoc and terms from a previous topic creation step;\n            %if not &useTopicCreationTbD. %then %do;\n                proc cas;\n                    session _etm_sess;\n\n                    output log;\n\n                    textMining.tmMine /\n                        documents = \"_etm_lang_&&_etm_lang&i.\"\n                        text = \"&textCol_1_name_base.\"\n                        docid = \"_etm_ID\"\n                        parent = {name = \"_etm_parent_&&_etm_lang&i.\", replace = True}\n                        terms = {name = \"_etm_terms_&&_etm_lang&i.\", replace = True}\n                        stopList = {name = \"_etm_&&_etm_lang&i.._stoplist\"}\n                        nounGroups = False\n                        tagging = False;\n                run;\n            %end;\n\n            proc cas;\n                session _etm_sess;\n\n                output log;\n\n                boolRule.brTrain /\n                    table = \"_etm_parent_&&_etm_lang&i.\"\n                    docid = '_document_'\n                    termid = '_termnum_'\n\n                    gPositive = &gPosBR.\n                    mPositive = &mPosBR.\n                    gNegative = &gNegBR.\n                    mNegative = &mNegBR.\n\n                    minSupports = &minSupportsBR.\n                    maxCandidates = &maxCandidatesBR.\n                    maxTriesIn = &maxTriesInBR.\n                    maxTriesOut = &maxTriesOutBR.\n\n                    docinfo = {\n                        table = \"_etm_lang_&&_etm_lang&i.\",\n                        id = '_etm_ID',\n                        targetType = \"&boolRuleTargetType.\"\n                        targets = {\"&boolRuleTarget_1_name_base.\"}\n                    }\n\n                    termInfo = {table = \"_etm_terms_&&_etm_lang&i.\", id = '_termnum_', label = '_term_'}\n                    casOuts = {rules = {name = \"_etm_rules_&&_etm_lang&i.\", replace = True}\n                        ruleTerms = {name = \"_etm_ruleTerms_&&_etm_lang&i.\", replace = True}\n                        candidateTerms = {name = \"_etm_cnddtTerms_&&_etm_lang&i.\", replace = True}\n                    };\n            run;\n\n            proc sql noprint;\n                select _ruleid_,\n                    compress(translate(strip(_rule_),'|','&'),' ~')\n                    into : _etm_ranks separated by '|', : _etm_terms separated by '|'\n                    from _etm_cas._etm_rules_&&_etm_lang&i.\n                        order by _ruleid_;\n            quit;\n            \n            data work._etm_boolRule_base;\n                set &outTable.;\n            \n                %do j=1 %to &sqlobs.;\n                    _etm_BR_&j.=(find(&textCol_1_name_base.,\"%scan(&_etm_terms.,&j.,'|')\",'i') gt 0);\n                    Label _etm_BR_&j.=\"BoolRule_&j.: %scan(&_etm_terms.,&j.,'|')\";\n                %end;\n            run;\n            \n            proc sort data=work._etm_boolRule_base;\n                by _etm_ID;\n            run;\n\n            data &outTable.;\n                merge &outTable. work._etm_boolRule_base;\n                by _etm_ID;\n            run;\n            \n            proc sort data=_etm_cas._etm_rules_&&_etm_lang&i. out=work._etm_butterfly;\n                by _ruleid_;\n            run;\n            \n            data work._etm_butterfly;\n                retain lrecall;\n                set work._etm_butterfly;\n                \n                rPrecision = _RuleTP_ / _RuleSupport_;\n                if _n_ eq 1 then rRecall = _Recall_;\n                if _n_ gt 1 then rRecall = _Recall_ - lrecall;\n                lRecall = _Recall_;\n            run;\n            \n            data work._etm_butterfly;\n                set work._etm_butterfly;\n            \n                rPrecision = -rPrecision;\n                rRecall = -rRecall;\n                Zero = 0;\n                Rule1    = strip(_rule_)||' ('||strip(put(_RuleSupport_, 8.))||')';\n            \n                call symputx('_etm_Precision', put(_Precision_, f4.2));\n                call symputx('_etm_Recall', put(_Recall_, f4.2));\n            run;\n            \n            proc format;\n                picture positive low-<0='0000'\n                    0<-high='0000';\n            run;\n            \n            Title1 \"Top 100 Boole Rules for Text Variable &textCol_1_name_base. and Target Variable &boolRuleTarget_1_name_base.\";\n            Title2 \"Filter Criteria: gPositive=&gPosBR. mPositive=&mPosBR. gNegative=&gNegBR. mNegative=&mNegBR.\";\n            \n            ods layout gridded columns = 2;\n            ods region;\n            ods graphics on / width = 800 Height = 1850;\n            proc sgplot data = work._etm_butterfly(obs = 100) noautolegend;\n            \n            Title \"Single Rule - Support - Cumul. Rule\";\n            footnote;\n            \n            format _Precision_ _Recall_ rPrecision rRecall positive.;\n            hbarparm category=rule1 response=_precision_ / dataskin=gloss name='Precision'\n                fillattrs=graphdata1  datalabelattrs=(size=10) transparency=0;\n            hbarparm category=rule1 response=rPrecision /  name='rPrecision'\n                fillattrs=graphdata1  datalabelattrs=(size=10) dataskin=gloss transparency=0;\n            hbarparm category=rule1 response=_Recall_ / dataskin=gloss name='Recall'\n                fillattrs=graphdata2  datalabelattrs=(size=10) transparency=0;\n            hbarparm category=rule1 response=rRecall / dataskin=gloss name='rRecall'\n                fillattrs=graphdata2  datalabelattrs=(size=10) transparency=0;\n            refline &_etm_Precision. / axis=x label=\"Cumultive Precision=&_etm_Precision.\"\n                labelloc=inside labelpos=min lineattrs=graphdata1;\n            refline &_etm_Recall. / axis=x label=\"Cumultive Recall=&_etm_Recall.\"\n                labelloc=inside labelpos=max  lineattrs=graphdata2;\n            scatter x=zero y=Rule1 / markerchar=Rule1 markercharattrs=(size=8  color=black);\n            keylegend 'Precision' 'Recall' 'F1';\n            xaxis values=(-1 to 1 by .2)  grid offsetmin=0.05 offsetmax=0.05 values=(-1 to 1 by .2) display=(nolabel)\n            Label='Single Prec & Rec - Rule(Support) - Cumul. Prec & Rec';\n            yaxis display=(noticks novalues nolabel);\n            scatter y=rule1 x=_f1_  / markerattrs=(Color=red symbol='CircleFilled' size=2) name=\"_F1_\" legendlabel=\"F1\";\n            run;\n            \n            data work._etm_butterfly;\n                set work._etm_butterfly;\n\n                rPrecision=-rPrecision;\n                rRecall=-rRecall;\n            run;\n            \n            ods region;\n            proc print data=work._etm_butterfly(Obs=100) label;\n                format rPrecision rRecall  _Precision_ _Recall_  _F1_ f5.3;\n                Id _RuleID_ _Rule_;\n                var rPrecision rRecall _RuleSupport_ _Precision_ _Recall_  _F1_ _RuleTP_ _RuleFP_  _RuleSetTP_ _RuleSetFP_ _RuleSetSupport_;\n            run;\n            ods layout end;\n            title;\n            ods;\n\n            * Remove datasets;\n            proc datasets library=work nolist;\n                delete _etm_butterfly _etm_boolRule_base;\n            run; quit;\n\n            * Remove the Custom Format;\n            proc catalog cat=work.formats;\n                delete positive / et=format;\n            run;\n        %end;\n    %mend _etm_create_boolRule;\n\n    %_etm_create_boolRule;\n\n    * Remove the macro;\n    proc catalog cat=work.sasmacr;\n        delete _etm_create_boolRule.macro;\n    run; quit;\n\n%end;\n\n* This dataset is used by different actions that run for each language in the dataset;\n%if &profileText. or &createTopics. or &createPredefinedConcepts. or &useCustomConcepts. or &createBoolRules. %then %do;\n    * Remove language translation dataset;\n    proc datasets library=work nolist;\n        delete _etm_lang_trans;\n    run; quit;\n%end;\n\n* This dataset is used by actions that levarage the custom concepts;\n%if &useCustomConcepts. %then %do;\n    * Remove datasets;\n    proc datasets library=work nolist;\n        delete _etm_all_custom_concepts;\n    run; quit;\n%end;\n\n%if &useTextAnalytics. %then %do;\n    * End the CAS session;\n    cas _etm_sess terminate;\n%end;"}}
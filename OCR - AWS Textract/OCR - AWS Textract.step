{"creationTimeStamp":"2023-12-15T08:27:29.505Z","modifiedTimeStamp":"2024-01-08T11:07:45.497Z","createdBy":"gerjch","modifiedBy":"gerjch","name":"OCR - AWS Textract.step","displayName":"OCR - AWS Textract.step","localDisplayName":"OCR - AWS Textract.step","properties":{},"links":[{"method":"GET","rel":"self","href":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","uri":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","type":"application/vnd.sas.data.flow.step"},{"method":"GET","rel":"alternate","href":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","uri":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","type":"application/vnd.sas.data.flow.step.summary"},{"method":"GET","rel":"up","href":"/dataFlows/steps","uri":"/dataFlows/steps","type":"application/vnd.sas.collection","itemType":"application/vnd.sas.data.flow.step.summary"},{"method":"PUT","rel":"update","href":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","uri":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","type":"application/vnd.sas.data.flow.step","responseType":"application/vnd.sas.data.flow.step"},{"method":"DELETE","rel":"delete","href":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","uri":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9"},{"method":"GET","rel":"transferExport","href":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","uri":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","responseType":"application/vnd.sas.transfer.object"},{"method":"PUT","rel":"transferImportUpdate","href":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","uri":"/dataFlows/steps/a604ad78-aad0-44d3-9f16-ed7ff92a7fc9","type":"application/vnd.sas.transfer.object","responseType":"application/vnd.sas.summary"}],"metadataVersion":0.0,"version":2,"type":"code","flowMetadata":{"inputPorts":[{"name":"ocr_input_table","displayName":"ocr_input_table","localDisplayName":"ocr_input_table","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table"}],"outputPorts":[{"name":"_output1","displayName":"_output1","localDisplayName":"_output1","minEntries":1,"maxEntries":1,"defaultEntries":0,"type":"table","supportsView":false,"requiresStructure":false},{"name":"_output2","displayName":"_output2","localDisplayName":"_output2","minEntries":0,"maxEntries":1,"defaultEntries":0,"type":"table","supportsView":false,"requiresStructure":false}]},"ui":"{\n\t\"showPageContentOnly\": true,\n\t\"pages\": [\n\t\t{\n\t\t\t\"id\": \"pageOptions\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Extraction Options\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"extraction_settings\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Extraction settings\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_type\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"What kind of data do you want to extract?\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"text\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Text\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"form\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Form\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_level\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"On which level should the the text be extracted?\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"Word\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"Line\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"Paragraph\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"Page\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"text\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_form_type\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"What kind of form do you want to extract?\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"FORMS\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Forms\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"Form2\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"ocr_input_settings\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Input\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_file_location\",\n\t\t\t\t\t\t\t\"type\": \"radiogroup\",\n\t\t\t\t\t\t\t\"label\": \"Where are the files located?\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"local\",\n\t\t\t\t\t\t\t\t\t\"label\": \"SAS Viya\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"s3_bucket\",\n\t\t\t\t\t\t\t\t\t\"label\": \"S3 Bucket\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_input_type_viya\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"What documents should be processed?\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"file\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Single file (path)\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"list\",\n\t\t\t\t\t\t\t\t\t\"label\": \"A list of files (table)\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"local\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textSingleFileHint\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Please note that files can only be read from the SAS Server. Files located in SAS Content can't be accessed. \",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"local\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_document_path_viya\",\n\t\t\t\t\t\t\t\"type\": \"path\",\n\t\t\t\t\t\t\t\"label\": \"Select the file for processing:\",\n\t\t\t\t\t\t\t\"pathtype\": \"file\",\n\t\t\t\t\t\t\t\"placeholder\": \"sasserver:/path/to/file/on/saserver\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"local\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$ocr_input_type_viya\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"file\"\n\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_input_type_bucket\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"What documents should be processed?\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"list\",\n\t\t\t\t\t\t\t\t\t\"label\": \"A list of files (table)\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"bucket\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Everything in this S3 Bucket\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"s3_bucket\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"s3_bucket_information_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Please note that the bucket has to be in the same AWS region (see AWS page) in which the endpoint is located.\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"s3_bucket\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$ocr_input_type_bucket\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"bucket\"\n\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"aws_s3_bucket_name\",\n\t\t\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\t\t\"label\": \"Name of the S3 bucket containing the documents:\",\n\t\t\t\t\t\t\t\"placeholder\": \" \",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"s3_bucket\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$ocr_input_type_bucket\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"bucket\"\n\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_input_table\",\n\t\t\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\t\t\"label\": \"Select the table that lists the files:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"local\"\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_input_type_viya\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"list\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"|\",\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"s3_bucket\"\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_input_type_bucket\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"list\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_doc_column\",\n\t\t\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\t\t\"label\": \"Select the column that contains the file paths:\",\n\t\t\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\t\t\"columntype\": \"c\",\n\t\t\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\t\t\"min\": null,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"local\"\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_input_type_viya\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"list\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"|\",\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_file_location\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"s3_bucket\"\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\"$ocr_input_type_bucket\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"list\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"table\": \"ocr_input_table\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"output_settings\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Output\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"_output1\",\n\t\t\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\t\t\"label\": \"Select an output table:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"output_status_table\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Output OCR status table\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_output_information_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Please note that you need to make sure that the output for the status table is manually connected to a table.\",\n\t\t\t\t\t\t\t\"visible\": \"$output_status_table\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"_output2\",\n\t\t\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\t\t\"label\": \"Choose an output table for the OCR status information:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"$output_status_table\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"pageAWS\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"AWS Connection\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"aws_access_key\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"AWS Access Key:\",\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"aws_secret_key\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"AWS Secret Key:\",\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textCredentialHint\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"Hint: A more secure and convenient method is to set your credentials as macro variables in the Autoexec  file (go to Options -> Autoexec file). \\nOnce declared, you can simply reference these variables in these fields (e.g. '&<name_of_secret_macro>').\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"aws_region_name\",\n\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\"label\": \"Select AWS Region:\",\n\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"us-east-2\",\n\t\t\t\t\t\t\t\"label\": \"US East (Ohio)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"us-east-1\",\n\t\t\t\t\t\t\t\"label\": \"US East (N. Virginia)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"us-west-1\",\n\t\t\t\t\t\t\t\"label\": \"US West (N. California)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"us-west-2\",\n\t\t\t\t\t\t\t\"label\": \"US West (Oregon)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ap-south-1\",\n\t\t\t\t\t\t\t\"label\": \"Asia Pacific (Mumbai)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ap-northeast-2\",\n\t\t\t\t\t\t\t\"label\": \"Asia Pacific (Seoul)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ap-southeast-1\",\n\t\t\t\t\t\t\t\"label\": \"Asia Pacific (Singapore)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ap-southeast-2\",\n\t\t\t\t\t\t\t\"label\": \"Asia Pacific (Sydney)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"ca-central-1\",\n\t\t\t\t\t\t\t\"label\": \"Canada (Central)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"eu-central-1\",\n\t\t\t\t\t\t\t\"label\": \"Europe (Frankfurt)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"eu-west-1\",\n\t\t\t\t\t\t\t\"label\": \"Europe (Ireland)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"eu-west-2\",\n\t\t\t\t\t\t\t\"label\": \"Europe (London)\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"value\": \"eu-west-3\",\n\t\t\t\t\t\t\t\"label\": \"Europe (Paris)\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textAWSRegion\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"Selecting an appropriate AWS region for OCR services is crucial, as each region varies in service availability, data regulation compliance, and proximity to your location, impacting performance and legal adherence. If experiencing errors or latency, consider a region closer to you with available Textract service. For a comprehensive list of AWS regions and services, refer to the \\\"AWS Region List\\\" under the \\\"Documentation\\\" section in the \\\"About\\\" page. Additionally, verify that your credentials are valid for the chosen region.\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"pageAdvanced\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Advanced Options\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"ocr_advanced_connection\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Connection\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"n_connection_retries\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of retries for endpoint connection:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"retry_delay\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Seconds between retry attempts:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 10,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"ocr_advanced_paragraph\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"OCR\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\"$ocr_level\",\n\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\"Paragraph\"\n\t\t\t\t\t],\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_advanced_information_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"AWS Textract doesn't provide the OCR results on a paragraph level. Hence, paragraphs are detected after the fact by looking for text lines that are close / overlapping. \",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_level\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"Paragraph\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"overlap_threshold\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Threshold for detecting paragraphs:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"integer\": false,\n\t\t\t\t\t\t\t\"min\": 0.001,\n\t\t\t\t\t\t\t\"max\": 0.5,\n\t\t\t\t\t\t\t\"stepsize\": 0.05,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_level\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"Paragraph\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"pageAbout\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"About\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textAbout\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"OCR - AWS Textract\\n==============\\n\\nThis custom step uses the AWS Textract service to perform different types of OCR on files that can be stored in S3 buckets or on the SAS Compute file system.\\n\\nNOTE: The usage of this step requires an AWS account and credentials with the appropriate rights to access the AWS Textract service. \\n\\nThe following Textract actions are currently supported: \\n  * DetectDocumentText (text extraction)\\n  * AnalyzeDocument (form extraction)\\n\\nThe following file types are currently supported:\\n  * .png\\n  * .jpg / .jpeg\\n\\nIn the output table options, you can specify an additional \\\"status\\\" table that outputs additional information about the status of the requests to the AWS Textract API.\\n\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"sectionPrereqs\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Pre-requisites\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textPrereqs\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Tested on Viya version Stable 2023.10\\n\\n * pandas\\n * numpy\\n * boto3\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"sectionDocumentation\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Documentation\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textDocumentation\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"* PROC PYTHON (https://go.documentation.sas.com/doc/en/pgmsascdc/default/proc/p1iycdzbxw2787n178ysea5ghk6l.htm)\\n\\n * AWS Textract\\n(https://docs.aws.amazon.com/textract/)\\n\\n * AnalyzeDocument Action\\n(https://docs.aws.amazon.com/textract/latest/dg/API_AnalyzeDocument.html)\\n\\n * DetectDocumentText Action\\n(https://docs.aws.amazon.com/textract/latest/dg/API_DetectDocumentText.html)\\n\\n * BOTO3 API Reference\\n(https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html)\\n\\n * AWS Region List\\n(https://docs.aws.amazon.com/general/latest/gr/textract.html)\\n\\n* AWS Credential Management (IAM):\\n(https://docs.aws.amazon.com/textract/latest/dg/security-iam.html)\\n\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"sectionChangelog\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Changelog\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textChangelog\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"* Version: 1.0 (08JAN2024)\\n      - Initial version\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textAuthor\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"This custom step was created by Jannic Horst (jannic.horst@sas.com).\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t],\n\t\"syntaxversion\": \"1.3.0\",\n\t\"values\": {\n\t\t\"ocr_type\": {\n\t\t\t\"value\": \"text\",\n\t\t\t\"label\": \"Text\"\n\t\t},\n\t\t\"ocr_level\": {\n\t\t\t\"value\": \"Line\"\n\t\t},\n\t\t\"ocr_form_type\": {\n\t\t\t\"value\": \"FORMS\",\n\t\t\t\"label\": \"Forms\"\n\t\t},\n\t\t\"ocr_file_location\": {\n\t\t\t\"value\": \"local\",\n\t\t\t\"label\": \"SAS Viya\"\n\t\t},\n\t\t\"ocr_input_type_viya\": {\n\t\t\t\"value\": \"file\",\n\t\t\t\"label\": \"Single file (path)\"\n\t\t},\n\t\t\"ocr_document_path_viya\": \"\",\n\t\t\"ocr_input_type_bucket\": {\n\t\t\t\"value\": \"bucket\",\n\t\t\t\"label\": \"Everything in this S3 Bucket\"\n\t\t},\n\t\t\"aws_s3_bucket_name\": \" \",\n\t\t\"ocr_input_table\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"ocr_doc_column\": [],\n\t\t\"_output1\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"output_status_table\": false,\n\t\t\"_output2\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"aws_access_key\": \"\",\n\t\t\"aws_secret_key\": \"\",\n\t\t\"aws_region_name\": {\n\t\t\t\"value\": \"eu-central-1\",\n\t\t\t\"label\": \"Europe (Frankfurt)\"\n\t\t},\n\t\t\"n_connection_retries\": 3,\n\t\t\"retry_delay\": 2,\n\t\t\"overlap_threshold\": 0.1\n\t}\n}","templates":{"SAS":"proc python restart;\nsubmit;\n\n# Imports\nimport pandas as pd\nimport numpy as np\nimport os\nimport functools\nimport time\nimport sys\nimport boto3\nfrom botocore.exceptions import ClientError, EndpointConnectionError\n\n\n################### DEFINE PARAMETERS ###################\n# General Input\nocr_type = SAS.symget(\"ocr_type\") # text | form \nocr_level = SAS.symget(\"ocr_level\") # word | line | paragraph | page\nocr_form_type = SAS.symget(\"ocr_form_type\") # TABLES |FORMS| QUERIES |SIGNATURES \nocr_file_location = SAS.symget(\"ocr_file_location\") # local | s3_bucket\nocr_input_table_name = SAS.symget(\"ocr_input_table\") # table containing file paths\nocr_doc_column = SAS.symget(\"ocr_doc_column\") # column that holds the path\n\n# File location dependent (local / S3 bucket)\nif ocr_file_location == 'local':\n\tocr_input_type = SAS.symget(\"ocr_input_type_viya\") # file | list \n\tocr_document_path = SAS.symget(\"ocr_document_path_viya\") # for single file ocr\n\taws_s3_bucket_name = ''\nelse:\n\tocr_input_type = SAS.symget(\"ocr_input_type_bucket\") # list | bucket\n\taws_s3_bucket_name = SAS.symget(\"aws_s3_bucket_name\")\n\tocr_document_path = ''\n\n# When input type is 'list'\nif ocr_input_type == 'list':\n\tocr_input_table = SAS.sd2df(ocr_input_table_name)\nelse:\n\tocr_input_table = ''\n\n# When input type is 'file'\nif ocr_input_type == 'file':\n\ttry:\n\t\tocr_document_path = ocr_document_path.split(':', 1)[1]\n\texcept Exception as e:\n\t\tSAS.logMessage(\"Please select a valid path. Files have to be located on SAS Server (not SAS Content)!\", 'error')\n\t\tsys.exit()\n\n# Ouput\noutput_status_table =  SAS.symget(\"output_status_table\")\n\n# Advanced \noverlap_threshold = float(SAS.symget(\"overlap_threshold\")) # for paragrpah identification\nn_connection_retries = int(SAS.symget(\"n_connection_retries\")) # Default is 3\nretry_delay = int(SAS.symget(\"retry_delay\")) # Default is 2\n\n# AWS\naws_region_name = SAS.symget(\"aws_region_name\")  # eu-central-1 | us-east-1 | ...\naws_access_key = SAS.symget(\"aws_access_key\")\naws_secret_key = SAS.symget(\"aws_secret_key\")\n\n\n\n##################### HELPER FUNCTIONS #####################\ndef retry_on_endpoint_connection_error(max_retries=3, delay=2):\n    \"\"\"\n    This is a decorator function that allows a function to retry execution when an EndpointConnectionError occurs.\n\n    Parameters:\n    max_retries (int): The maximum number of retries if an EndpointConnectionError occurs. Default is 3.\n    delay (int): The delay (in seconds) between retries. Default is 2.\n\n    Returns:\n    wrapper function: The decorated function that includes retry logic.\n    \"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            retries = 0\n            while retries < max_retries:\n                try:\n                    return func(*args, **kwargs)\n                except EndpointConnectionError as e:\n                    SAS.logMessage(f'Retrying due to EndpointConnectionError: {e}')\n                    retries += 1\n                    time.sleep(delay)\n                except Exception as e:\n                    raise e  # Let other exceptions be handled by the utility class\n\n            if retries == max_retries:\n                SAS.logMessage(f\"Max retries ({max_retries}) reached. Unable to complete operation.\", 'warning')\n                raise RuntimeError(\"Max retries to contact AWS Textract endpoint reached. Unable to complete operation.\")\n        return wrapper\n\n    return decorator\n\nclass ErrorHandlingUtility:\n    \"\"\"\n    A utility class for handling exceptions related to Textract operations.\n\n    This class provides a static method to handle exceptions that may occur during Textract operations.\n    It specifically handles EndpointConnectionError and ClientError exceptions, logging the error message and re-raising the exception.\n    For other types of exceptions, they are simply re-raised.\n\n    Methods:\n    handle_textract_exception(e: Exception, file: str) -> pd.Series or None:\n        Handles Textract related exceptions, logs the error message, and re-raises the exception.\n    \"\"\"\n    @staticmethod\n    def handle_textract_exception(e, file):\n        # handling EndpointConnectionError after number of retries\n        if isinstance(e, EndpointConnectionError):\n            status = pd.Series([file, False, type(e).__name__, str(e), pd.NA, pd.NA, pd.NA],\n                               index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n            \n            raise e\n\n        # handle ClientErrors\n        elif isinstance(e, ClientError):\n            error_code = e.response['Error']['Code']\n            if error_code in ['AccessDeniedException', 'InvalidParameterException', 'ServiceQuotaExceededException', 'UnrecognizedClientException']:\n                SAS.logMessage(f\"{error_code} occurred while processing documents.{e}\", 'error')\n                raise e\n                \n            status = pd.Series([file, False, type(e).__name__, str(e), pd.NA, pd.NA, pd.NA],\n                               index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n            return status\n\n        else:\n            raise e  # Re-raise other exceptions\n\n\n##################### FILE PREP STRATEGIES #####################\nclass DocumentInputStrategy:\n    \"\"\" Document preparation strategy interface\"\"\"\n    def process_files(self):\n        pass\n\nclass SingleFileStrategy(DocumentInputStrategy):\n    \"\"\" Document preparation strategy for single file input \"\"\"\n\n    def __init__(self, params):\n        self.ocr_document_path = params.get('ocr_document_path')\n\n    def process_files(self):\n        \"\"\" Return the single file path as a dataframe \"\"\"\n        return pd.DataFrame({'file_path': [self.ocr_document_path]})\n\nclass FileListStrategy(DocumentInputStrategy):\n    \"\"\" Document preparation strategy for list of files \"\"\"\n\n    def __init__(self, params):\n        self.ocr_input_table = params.get('ocr_input_table')\n        self.ocr_doc_column = params.get('ocr_doc_column')\n\n    def process_files(self):\n        \"\"\" Filter the input table to only include the specified path column \"\"\"\n        # filter the input table to only include path column\n        file_list = self.ocr_input_table[[self.ocr_doc_column]]\n        file_list = file_list.rename(columns={self.ocr_doc_column: 'file_path'})\n\n        return file_list\n\nclass S3BucketStrategy(DocumentInputStrategy):\n    \"\"\" Document preparation strategy for S3 bucket \"\"\"\n    def __init__(self, params):\n        self.aws_region = params.get('aws_region')\n        self.s3_bucket_name = params.get('s3_bucket_name')\n        self.aws_access_key = params.get('aws_access_key')\n        self.aws_secret_key = params.get('aws_secret_key')\n\n    def process_files(self):\n        \"\"\" Return a list of files in the specified S3 bucket \"\"\"\n        s3 = boto3.resource('s3',  \n                            aws_access_key_id=self.aws_access_key,\n                            aws_secret_access_key=self.aws_secret_key)\n        \n        s3_bucket = s3.Bucket(self.s3_bucket_name)\n\n        file_paths = []\n        try:\n            for s3_file in s3_bucket.objects.all():\n                file_paths.append(s3_file.key)\n        except ClientError as e:\n            if e.response['Error']['Code'] == 'InvalidS3ObjectException':\n                SAS.logMessage(f\"Invalid S3 object exception occurred.\", 'error')\n                raise e\n            else:\n                SAS.logMessage(f\"An error occurred: {e}\", 'error')\n        \n        file_list = pd.DataFrame({'file_path': file_paths})\n\n        return file_list\n\nclass DocumentPreparer:\n    \"\"\" Document preparation class that uses a strategy pattern to prepare documents for OCR \"\"\"\n    def __init__(self, ocr_input_type:str, **kwargs):\n        self.ocr_input_type = ocr_input_type\n        self.strategy = self._strategies.get(ocr_input_type)(**kwargs)\n\n    _strategies = {\n        \"file\": SingleFileStrategy,\n        \"list\": FileListStrategy,\n        \"bucket\": S3BucketStrategy,\n    }\n\n    def process_files(self):\n        return self.strategy.process_files()\n\n\n###################### OCR STRATEGIES #####################\nclass OCRStrategy:\n    \"\"\" OCR strategy interface \"\"\"\n    def __init__(self, file_list, params):\n        self.file_list = file_list\n        self.params = params\n\n    def process_ocr(self):\n        pass\n\n    def parse_result(self):\n        self\n\nclass ExtractText(OCRStrategy):         # Textract.DetectDocumentText\n    \"\"\" OCR strategy for extracting text from documents using Textract.DetectDocumentText \"\"\"\n    def __init__(self, file_list, ocr_params):\n        #super().__init__(ocr_params)\n        self.file_list = file_list\n        self.aws_region_name = ocr_params[\"aws_region_name\"]\n        self.aws_ocr_access_key = ocr_params[\"aws_access_key\"]\n        self.aws_ocr_secret_key = ocr_params[\"aws_secret_key\"]\n        self.level = ocr_params[\"ocr_level\"]\n\n        self.ocr_file_location = ocr_params[\"ocr_file_location\"]\n        self.aws_s3_bucket_name = ocr_params[\"aws_s3_bucket_name\"]\n\n        self.overlap_threshold = ocr_params[\"overlap_threshold\"]\n\n    def merge_lines(self, df):\n        \"\"\" Merge extracted text lines into paragraphs or pages \n        \n        Parameters:\n        df (pandas.DataFrame): dataframe containing the text lines\n\n        Returns:\n        pandas.DataFrame: dataframe containing the text in paragraphs or pages\n        \"\"\"\n        concatenated_text = \"\\n \".join(df['Text'])\n\n        # Calculate overall bounding box\n        min_left = df['Left'].min()\n        min_top = df['Top'].min()\n        max_width = (df['Width'] + df['Left']).max() - min_left\n        max_height = (df['Height'] + df['Top']).max() - min_top\n        average_confidence = df['Confidence'].mean()\n\n        page_data = {'Text': [concatenated_text],\n                    'Width': [max_width],\n                    'Height': [max_height],\n                    'Left': [min_left],\n                    'Top': [min_top],\n                    'Confidence': [average_confidence]}\n\n        return pd.DataFrame(page_data)\n\n    def detect_paragraphs(self, df, overlap_threshold):\n        \"\"\" Detect paragraphs in the extracted text based on vertical overlap of extracted text lines. \n        \n        Parameters:\n        df (pandas.DataFrame): dataframe containing the text lines\n        overlap_threshold (float): the maximum vertical distance between two lines to be considered as part of the same paragraph\n        \n        Returns:\n        pandas.DataFrame: dataframe containing the text in paragraphs\n        \"\"\"\n        # Sort lines by the 'Top' coordinate\n        df = df.sort_values(by='Top').reset_index(drop=True)\n        overlap_threshold = self.overlap_threshold\n\n        # Initialize a list to store paragraphs\n        paragraphs = []\n        current_paragraph = []\n        paragraph_index = 0\n        result_data = []\n\n        # Iterate through rows \n        for index, row in df.iterrows():\n            if not current_paragraph:\n                current_paragraph.append({'Text': row['Text'], 'Width': row['Width'], 'Height': row['Height'],\n                                        'Left': row['Left'], 'Top': row['Top'], 'Confidence': row['Confidence']})\n            else:\n                # Check if the current row overlaps vertically with the last row in the current paragraph\n                if (row['Top'] - df.at[index - 1, 'Top']) <= overlap_threshold:\n                    current_paragraph.append({'Text': row['Text'], 'Width': row['Width'], 'Height': row['Height'],\n                                            'Left': row['Left'], 'Top': row['Top'], 'Confidence': row['Confidence']})\n                else:\n                    paragraphs.append(current_paragraph)\n                    current_paragraph = [{'Text': row['Text'], 'Width': row['Width'], 'Height': row['Height'],\n                                        'Left': row['Left'], 'Top': row['Top'], 'Confidence': row['Confidence']}]\n                    paragraph_index += 1\n\n        # Append the last paragraph\n        paragraphs.append(current_paragraph)\n\n        # Create the resulting DataFrame\n        for i, paragraph in enumerate(paragraphs):\n            for line in paragraph:\n                result_data.append({'Paragraph': int(i), 'Text': line['Text'], 'Width': line['Width'], 'Height': line['Height'],\n                                    'Left': line['Left'], 'Top': line['Top'], 'Confidence': line['Confidence']})\n\n        return pd.DataFrame(result_data)\n\n    def parse_result(self,overlap_threshold=0.1):\n        \"\"\" Parse the Textract response into a dataframe\n        \n        Parameters:\n        overlap_threshold (float): the maximum vertical distance between two lines to be considered as part of the same paragraph\n\n        Returns:\n        pandas.DataFrame: dataframe containing the parsed text\n         \"\"\"\n        # results on page or paragraph level are not provided natively\n        level = self.level\n        result = self.response\n\n        if (level.upper() == \"PAGE\" or level.upper() == \"PARAGRAPH\"):\n            lod = \"LINE\"\n        else:\n            lod = level.upper()\n\n        # initialize arrays\n        text = []\n        text_type = []\n        block_types = []\n        widths = []  \n        heights = []\n        lefts = []\n        tops = []\n        confidences = []\n\n        # Extract words / lines from the Textract result\n        for block in result[\"Blocks\"]:\n            if block[\"BlockType\"] == lod:\n                text.append(block[\"Text\"])\n                block_types.append(block[\"BlockType\"])\n                bounding_box = block[\"Geometry\"][\"BoundingBox\"]\n                widths.append(bounding_box[\"Width\"])\n                heights.append(bounding_box[\"Height\"])\n                lefts.append(bounding_box[\"Left\"])\n                tops.append(bounding_box[\"Top\"])\n                confidences.append(block.get(\"Confidence\", None))\n\n                # get the word type (only availabe when extracting on word level)\n                if (lod == \"WORD\"):\n                    text_type.append(block[\"TextType\"])\n                else:\n                    text_type.append(np.nan)\n\n        data = {\n            \"Text\": text,\n            \"BlockType\": block_types,\n            \"Width\": widths,\n            \"Height\": heights,\n            \"Left\": lefts,\n            \"Top\": tops,\n            \"Confidence\": confidences\n        }\n\n        df = pd.DataFrame(data)\n        \n        # transform for \"PAGE\" output\n        if (level.upper() == \"PAGE\"):\n            df = self.merge_lines(df)\n\n        # transform for \"PARAGRAPH\" output\n        elif (level.upper() == \"PARAGRAPH\"):\n            df = self.detect_paragraphs(df, overlap_threshold)\n            df = df.groupby('Paragraph').apply(self.merge_lines).reset_index(level='Paragraph')\n                \n        return df\n\n    @retry_on_endpoint_connection_error(max_retries=n_connection_retries, delay=retry_delay)\n    def detect_document_text(self, client, file, imageBytes=None):\n        \"\"\" Call the Textract.DetectDocumentText API\n        \n        Parameters:\n        client (boto3.client): boto3 client for Textract\n        file (str): the file path of the document to be processed\n        imageBytes (bytearray): the byte array of the document to be processed\n\n        Returns:\n        dict: the response from the Textract.DetectDocumentText API\n        \n        \"\"\"\n        if self.ocr_file_location == 'local': \n            response = client.detect_document_text(Document={'Bytes': imageBytes})\n        else: # documents are in s3 bucket\n            response = client.detect_document_text(Document={'S3Object': {'Bucket': self.aws_s3_bucket_name, 'Name': file}})\n\n        return response \n\n    def process_ocr(self):\n        \"\"\" Process the OCR on the documents in the file list\n        \n        Returns:\n        pandas.DataFrame: dataframe containing extracted and parsed text \n        \"\"\"\n        client = boto3.client('textract',\n                                aws_access_key_id = self.aws_ocr_access_key, \n                                aws_secret_access_key = self.aws_ocr_secret_key,\n                                region_name = aws_region_name)\n\n        result_df = pd.DataFrame(columns=['File'])\n        status_df = pd.DataFrame(columns=['File', 'Done', 'Error-Type','Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n\n        # iterate through all documents\n        for file in self.file_list['file_path']:\n            \n            # filter unsupported file types\n            _, file_extension = os.path.splitext(file) \n            if file_extension.lower() in '.pdf':  # special case, because people expect this to work\n                SAS.logMessage(\"PDF-Files are not supported! (will be skipped)\", 'warning')                    \n\n                status = pd.Series([file, False, 'File Format Error',   f\"'.{file_extension.lower()}' files are not supported. Convert to .PNG or .JPEG\", pd.NA, pd.NA, pd.NA],\n                                    index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n                continue\n            elif file_extension.lower() not in ['.jpg', 'jpeg', '.png']:\n                #raise ValueError(f\"Unsupported file type at '{file}'.\")\n                status = pd.Series([file, False, 'File Format Error',   f\"'.{file_extension.lower()}' files are not supported. Convert to .PNG or .JPEG\", pd.NA, pd.NA, pd.NA],\n                                    index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n            \n            # load files (if files are local)\n            if self.ocr_file_location == 'local':\n                try: \n                    with open(file, 'rb') as document:\n                        imageBytes = bytearray(document.read())\n                except Exception as e:\n                        SAS.logMessage(f\"An unexpected error occurred: {e}\", 'error')                    \n                        status = pd.Series([file, False, 'File Access Error',  e, pd.NA, pd.NA, pd.NA],\n                                        index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                        status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n                        continue\n\n            # call textract api\n            try:\n                if self.ocr_file_location == 'local':\n                    self.response = self.detect_document_text(client, file, imageBytes)\n                else:\n                    self.response = self.detect_document_text(client, file, )\n            except ClientError as e:\n                SAS.logMessage(f\"Client Error: {e}\", 'error')\n                status = ErrorHandlingUtility.handle_textract_exception(e, file)\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)\n            except Exception as e:\n                status = pd.Series([file, False, 'Textract-Error', f'{e}', pd.NA, pd.NA, pd.NA], #Unkonwn problem while parsing Textract response: \n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)  \n                raise e\n\n            # log files with erroneous calls \n            try:\n                if (self.response['ResponseMetadata']['HTTPStatusCode'] != 200):\n                    status = pd.Series([file, False, 'HTTP',  self.response['ResponseMetadata']['HTTPStatusCode'], pd.NA, pd.NA, pd.NA],\n                                    index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                    status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n                    continue\n            except:\n                pass\n            \n            # parse OCR result\n            try:\n                ocr_result = self.parse_result(self)\n            except Exception as e:\n                status = pd.Series([file, False, 'Parse-Error', f'{e}', pd.NA, pd.NA, pd.NA], #Unkonwn problem while parsing Textract response: \n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)  \n                continue\n\n            # track status of file processing\n            try:\n                status = pd.Series([file, True, '', '', \n                                ocr_result['Confidence'].mean(), \n                                ocr_result['Confidence'].max(), \n                                ocr_result['Confidence'].min()],\n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)\n            except KeyError as e:\n                status = pd.Series([file, False, 'KeyError', f'{e}', pd.NA, pd.NA, pd.NA], #Unkonwn problem while parsing Textract response: \n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)  \n                continue\n\n            # add result to dataframe\n            ocr_result['File'] = file\n            result_df = pd.concat([result_df, ocr_result], ignore_index=True)\n\n            \n        if self.level.upper() == 'PARAGRAPH': # for some reason this turns to a float at some point\n            result_df['Paragraph'] = result_df['Paragraph'].astype(int)\n\n        return result_df, status_df\n    \nclass ExtractForm(OCRStrategy):         # Textract.AnalyzeDocument\n    \"\"\" OCR strategy for extracting key-value pairs from documents using Textract.AnalyzeDocument \"\"\"\n\n    def __init__(self, file_list, ocr_params):\n        #super().__init__(ocr_params)\n        self.file_list = file_list\n        self.aws_region_name = ocr_params['aws_region_name']\n        self.aws_ocr_access_key = ocr_params[\"aws_access_key\"]\n        self.aws_ocr_secret_key = ocr_params[\"aws_secret_key\"]\n        self.ocr_file_location = ocr_params[\"ocr_file_location\"]\n        self.aws_s3_bucket_name = ocr_params[\"aws_s3_bucket_name\"]\n        self.ocr_form_type = ocr_params [\"ocr_form_type\"]\n\n    def find_value_block(self, key_block, value_map):\n        \"\"\" Find the value block for a given key block\n        \n        Parameters:\n        key_block (dict): the key block\n        value_map (dict): the value map\n        \n        Returns:\n        dict: the value block corresponding to the given key block \"\"\"\n        for relationship in key_block['Relationships']:\n            if relationship['Type'] == 'VALUE':\n                for value_id in relationship['Ids']:\n                    value_block = value_map[value_id]\n        return value_block\n\n    def get_text(self, result, blocks_map):\n        \"\"\" Get the text for a given block \n        \n        Parameters:\n        result (dict): the result containing the block\n        blocks_map (dict): the map of blocks\n        \n        Returns:\n        str: the text corresponding to the given block\n        \"\"\"\n        text = ''\n        if 'Relationships' in result:\n            for relationship in result['Relationships']:\n                if relationship['Type'] == 'CHILD':\n                    for child_id in relationship['Ids']:\n                        word = blocks_map[child_id]\n                        if word['BlockType'] == 'WORD':\n                            text += word['Text'] + ' '\n                        if word['BlockType'] == 'SELECTION_ELEMENT':\n                            if word['SelectionStatus'] == 'SELECTED':\n                                text += 'X '\n\n        return text\n\n    def parse_result(self, ocr_form_type):\n        \"\"\" Parse the Textract response into a dataframe\n        \n        Parameters:\n        ocr_form_type (str): the type of form to extract (FORMS, TABLES, SIGNATURES, or ALL)\n        \n        Returns:\n        pandas.DataFrame: dataframe containing the parsed key-value pairs \"\"\"\n        response = self.response\n\n        if ocr_form_type == 'FORMS':\n            blocks = response['Blocks']\n\n            key_map = {}\n            value_map = {}\n            block_map = {}\n\n            # create key and value map\n            for block in blocks:\n                block_id = block['Id']\n                block_map[block_id] = block\n                if block['BlockType'] == \"KEY_VALUE_SET\":\n                    if 'KEY' in block['EntityTypes']:\n                        key_map[block_id] = block\n                    else:\n                        value_map[block_id] = block\n\n            kv_data = []\n\n            # extract key-value data\n            for key_block_id, key_block in key_map.items():\n                value_block = self.find_value_block(key_block, value_map)\n                key_bounding_box = key_block['Geometry']['BoundingBox']  # BoundingBox for the key\n                value_bounding_box = value_block['Geometry']['BoundingBox']  # BoundingBox for the value\n\n                kv_data.append({\n                    'key': self.get_text(key_block, block_map),\n                    'value': self.get_text(value_block, block_map),\n                    'key_confidence': key_block['Confidence'],\n                    'value_confidence': value_block['Confidence'],\n                    'key_width' : key_bounding_box[\"Width\"],\n                    'key_height' :  key_bounding_box[\"Height\"],\n                    'key_left' : key_bounding_box[\"Left\"],\n                    'key_top' : key_bounding_box[\"Top\"],\n                    'value_width' : value_bounding_box[\"Width\"],\n                    'value_height' : value_bounding_box[\"Height\"],\n                    'value_left' : value_bounding_box[\"Left\"],\n                    'value_top' : value_bounding_box[\"Top\"],\n                })\n\n            df = pd.DataFrame(kv_data)\n\n        return df\n\n    @retry_on_endpoint_connection_error(max_retries=n_connection_retries, delay=retry_delay)\n    def analyze_document(self, client, file, imageBytes=None):\n        \"\"\" Call the Textract.AnalyzeDocument API \n        \n        Parameters:\n        client (boto3.client): boto3 client for Textract\n        file (str): the file path of the document to be processed\n        imageBytes (bytearray): the byte array of the document to be processed\n        \n        Returns:\n        dict: the response from the Textract.AnalyzeDocument API\n        \"\"\"\n        if self.ocr_file_location == 'local': \n            response = client.analyze_document(Document={'Bytes': imageBytes,},\n                                                FeatureTypes=[\"FORMS\"])   \n        else: # documents are in s3 bucket\n            response = client.analyze_document(Document={'S3Object': {'Bucket': self.aws_s3_bucket_name, \n                                                                        'Name': file}},\n                                                FeatureTypes=[\"FORMS\"])  \n\n        return response\n\n    def process_ocr(self):\n        \"\"\" Process the OCR on the documents in the file list\n        \n        Returns:\n        pandas.DataFrame: dataframe containing extracted and parsed key-value pairs\n        \"\"\"\n        client = boto3.client('textract',\n                                aws_access_key_id = self.aws_ocr_access_key, \n                                aws_secret_access_key = self.aws_ocr_secret_key,\n                                region_name = aws_region_name)\n        result_df = pd.DataFrame(columns=['File'])\n        status_df = pd.DataFrame(columns=['File', 'Done', 'Error-Type','Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n\n        # iterate through all documents\n        for file in self.file_list['file_path']:\n            \n            # filter unsupported file types\n            _, file_extension = os.path.splitext(file)\n\n            if file_extension.lower() in '.pdf':  # special case, because people expect this to work                      \n                status = pd.Series([file, False, 'File Format Error',   f\"'.{file_extension.lower()}' files are not supported. Convert to .PNG or .JPEG\", pd.NA, pd.NA, pd.NA],\n                                    index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n                continue\n            elif file_extension.lower() not in ['.jpg', 'jpeg', '.png']:\n                status = pd.Series([file, False, 'File Format Error',   f\"'.{file_extension.lower()}' files are not supported. Convert to .PNG or .JPEG\", pd.NA, pd.NA, pd.NA],\n                                    index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n            \n            # load files (if files are local)\n            if self.ocr_file_location == 'local':\n                try: \n                    with open(file, 'rb') as document:\n                        imageBytes = bytearray(document.read())\n                except Exception as e:\n                        SAS.logMessage(f\"An unexpected error occurred: {e}\", 'error') \n                        status = pd.Series([file, False, 'File Access Error',  e, pd.NA, pd.NA, pd.NA],\n                                        index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                        status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n                        continue\n           \n            # call textract api\n            try:\n                if self.ocr_file_location == 'local':\n                    self.response = self.analyze_document(client, file, imageBytes)\n                else:\n                    self.response = self.analyze_document(client, file)\n            except ClientError as e:\n                SAS.logMessage(f\"Client Error: {e}\", 'error') \n                status = ErrorHandlingUtility.handle_textract_exception(e, file)\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)\n            except Exception as e:\n                status = pd.Series([file, False, 'Textract-Error', f'{e}', pd.NA, pd.NA, pd.NA], #Unkonwn problem while parsing Textract response: \n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)  \n                raise e\n\n            # log files with erroneous calls \n            try:\n                if (self.response['ResponseMetadata']['HTTPStatusCode'] != 200):\n                    status = pd.Series([file, False, 'HTTP',  self.response['ResponseMetadata']['HTTPStatusCode'], pd.NA, pd.NA, pd.NA],\n                                    index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                    status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True) \n                    continue\n            except:\n                pass\n            \n            # parse OCR result\n            try:\n                ocr_result = self.parse_result(self.ocr_form_type)\n            except Exception as e:\n                status = pd.Series([file, False, 'Parse-Error', f'Unkonwn problem when parsing Textract response: {e}', pd.NA, pd.NA, pd.NA],\n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)  \n                continue\n            \n            # track status of file processing\n            try:\n                status = pd.Series([file, True, '', '', \n                                ocr_result[['key_confidence', 'value_confidence']].values.mean(), \n                                ocr_result[['key_confidence', 'value_confidence']].values.max(), \n                                ocr_result[['key_confidence', 'value_confidence']].values.min()],\n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)\n            except Exception as e:\n                status = pd.Series([file, True, 'No detections',  'No key-value pairs were detected', pd.NA, pd.NA, pd.NA],\n                                index=['File', 'Done', 'Error-Type', 'Message', 'Avg_Confidence', 'Max_Confidence', 'Min_Confidence'])\n                status_df = pd.concat([status_df, status.to_frame().T], ignore_index=True)\n                continue\n\n            # add result to dataframe\n            ocr_result['File'] = file\n            result_df = pd.concat([result_df, ocr_result], ignore_index=True)\n\n        return result_df, status_df\n\nclass OCRProcessor:\n    \"\"\" OCR processing class that uses a strategy pattern to process OCR on documents \"\"\"\n    \n    def __init__(self, ocr_type:str, file_list:pd.DataFrame, ocr_params:dict):\n        self.ocr_type = ocr_type \n        self.file_list = file_list\n        self.ocr_params = ocr_params\n\n        # Define the strategy mapping\n        self.strategy_mapping = {\n            (\"text\"): ExtractText,\n            (\"form\"): ExtractForm\n        }\n\n        # Get the strategy class, parameters and initiate strategy\n        strategy_class = self.strategy_mapping[(self.ocr_type)]\n        #strategy_params = ocr_params.get(\"strategy_params\", {})\n        self.strategy = strategy_class(self.file_list, ocr_params)\n\n    def process_ocr(self):\n        return self.strategy.process_ocr()\n\n\n################### EXECUTION ###################\n# Document Preparer\ninput_params={# General Input Parameters\n                'ocr_document_path': ocr_document_path,\n                'ocr_input_table': ocr_input_table,\n                'ocr_doc_column': ocr_doc_column,\n                'ocr_document_path': ocr_document_path,\n                \n                # AWS Parameter\n                'aws_region': aws_region_name,\n                's3_bucket_name': aws_s3_bucket_name,\n                'aws_access_key': aws_access_key,\n                'aws_secret_key': aws_secret_key\n                }\n\ndocument_preparer = DocumentPreparer(ocr_input_type = ocr_input_type, params = input_params)\n\ntry:\n    file_list = document_preparer.process_files()\nexcept Exception as e:\n    SAS.logMessage(e, 'error')\n    sys.exit()\n\n# OCR Processor\ntry:\n\tocr_params={# General OCR Parameters\n\t            'ocr_level': ocr_level,\n\t            'ocr_form_type': ocr_form_type,\n\t            'ocr_file_location': ocr_file_location,\n\t            'overlap_threshold': overlap_threshold,\n\t\n\t            # AWS Parameters\n\t            'aws_access_key': aws_access_key,\n\t            'aws_secret_key': aws_secret_key,\n\t            'aws_region_name': aws_region_name,\n\t            'aws_s3_bucket_name': aws_s3_bucket_name\n\t            }\n\tocr_processor = OCRProcessor(ocr_type = ocr_type,\n\t                             file_list = file_list,\n\t                             ocr_params = ocr_params\n\t                            )\n\t\n\tocr_result, processing_status = ocr_processor.process_ocr()\n\t\n\tn_total = file_list.shape[0]\n\tn_processed = processing_status['Done'].sum()\nexcept Exception as e:\n    SAS.logMessage(e, 'error')\n    sys.exit()\n\n# Final table\nif ocr_input_type == 'list': # merge with input table to retain other information\n    final_df = pd.merge(ocr_result, ocr_input_table, left_on='File',right_on=ocr_doc_column, how='left')\nelse: \n    final_df = ocr_result\n\nfinal_df = SAS.df2sd(final_df,SAS.symget(\"_output1\"))\nif output_status_table == '1':\n    processing_status = SAS.df2sd(processing_status,SAS.symget(\"_output2\"))\n\nSAS.logMessage(f'{int(n_processed)} out of {n_total} documents were processed.')\n\nendsubmit;\nrun;\n\nproc python terminate; quit; \n"}}